{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-38-92b4ebe9d0c5>\", line 8, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2158, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2079, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-104>\", line 2, in matplotlib\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2949, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/anaconda/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint, pformat\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cell(object):\n",
    "    def __init__(self):\n",
    "        self.is_terminal = False\n",
    "        self.policy = ''\n",
    "        self.value = 0\n",
    "    def __str__(self):\n",
    "        return pformat(self.__dict__)\n",
    "    def __repr__(self): return self.__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_bounds_rows = 3\n",
    "world_bounds_cols = 4\n",
    "world_input = np.array([[0,0,0,1], [0,np.nan,0,-1], [0,0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   1.],\n",
       "       [  0.,  nan,   0.,  -1.],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self, array):\n",
    "        cells = []\n",
    "        for row_idx, row in enumerate(array):\n",
    "            cells.append([])\n",
    "            for col_idx, value in enumerate(row):\n",
    "                cell = Cell()\n",
    "                cell.row = row_idx\n",
    "                cell.col = col_idx\n",
    "                cell.value = value\n",
    "                # TODO get reward from input\n",
    "                # If the value is nonzero, NaN, or +-Inf, set as reward too\n",
    "                cell.reward = value or 0\n",
    "                cell.blocks = np.isnan(value)\n",
    "                cells[row_idx].append(cell)\n",
    "            assert len(cells[row_idx]) == world_bounds_cols\n",
    "        assert len(cells) == world_bounds_rows\n",
    "        cells[0][3].is_terminal = True\n",
    "        cells[1][3].is_terminal = True\n",
    "        self.cells = cells\n",
    "\n",
    "    def policy(self):\n",
    "        return [[c.policy for c in rows] for rows in self.cells]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self.cells:\n",
    "            for cell in row:\n",
    "                yield cell\n",
    "\n",
    "    def as_array(self):\n",
    "        a = [ [cell.value for cell in row] for row in self.cells ]\n",
    "        return np.array(a)\n",
    "\n",
    "    def north(self, cell):\n",
    "        row = cell.row; col = cell.col\n",
    "        if row > 0:\n",
    "            row -= 1\n",
    "        return self._next_cell_if_not_blocked(cell, row, col)\n",
    "\n",
    "    def south(self, cell):\n",
    "        row = cell.row; col = cell.col\n",
    "        if row < world_bounds_rows-1:\n",
    "            row += 1\n",
    "        return self._next_cell_if_not_blocked(cell, row, col)\n",
    "\n",
    "    def west(self, cell):\n",
    "        row = cell.row; col = cell.col\n",
    "        if col > 0:\n",
    "            col -= 1\n",
    "        return self._next_cell_if_not_blocked(cell, row, col)\n",
    "\n",
    "    def east(self, cell):\n",
    "        row = cell.row; col = cell.col\n",
    "        if col < world_bounds_cols-1:\n",
    "            col += 1\n",
    "        return self._next_cell_if_not_blocked(cell, row, col)\n",
    "\n",
    "    def _next_cell_if_not_blocked(self, cell, row, col):\n",
    "        n = self.cells[row][col]\n",
    "        if n.blocks:\n",
    "            return cell\n",
    "        return n\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.as_array())\n",
    "    def __repr__(self): return self.__str__()\n",
    "\n",
    "class ValueIterationAlgo(object):\n",
    "    def __init__(self, discount_factor, world):\n",
    "        self.discount_factor = discount_factor\n",
    "        self.world = world\n",
    "\n",
    "    def update(self, state):\n",
    "        if state.is_terminal or state.blocks: return\n",
    "        max_pv = 0 # probability * value, as used in V(s) calculation\n",
    "        # Moves in NSEW order\n",
    "        moves_pvs = [\n",
    "            0.8*self.world.north(state).value + 0.1*self.world.west(state).value + 0.1*self.world.east(state).value,\n",
    "            0.8*self.world.south(state).value + 0.1*self.world.west(state).value + 0.1*self.world.east(state).value,\n",
    "            0.8*self.world.east(state).value + 0.1*self.world.north(state).value + 0.1*self.world.south(state).value,\n",
    "            0.8*self.world.west(state).value + 0.1*self.world.north(state).value + 0.1*self.world.south(state).value\n",
    "        ]\n",
    "        moves_directions = ['north', 'south', 'east', 'west']\n",
    "        max_idx = np.argmax(moves_pvs)\n",
    "        max_pv = moves_pvs[max_idx]\n",
    "        policy = moves_directions[max_idx]\n",
    "        state.value = self.discount_factor * max_pv + state.reward\n",
    "        state.policy = policy\n",
    "##        print locals()\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.__dict__)\n",
    "    def __repr__(self): return self.__str__()\n",
    "\n",
    "\n",
    "def done():\n",
    "    global world, prev_world\n",
    "    # If NaNs are in the inputs, we may get a warning. Ignore it and it won't affect the epsilon comparison because np.nan > epsilon is False\n",
    "    try:\n",
    "        diff = np.abs(world.as_array() - prev_world)\n",
    "    except RuntimeWarning:\n",
    "        pass\n",
    "    return not (diff > epsilon).any()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.0001\n",
    "discount_factor = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part_b():\n",
    "    global world, prev_world\n",
    "    world = GridWorld(world_input)\n",
    "    prev_world = np.ones_like(world_input) # init to something other than input\n",
    "    algo = ValueIterationAlgo(discount_factor, world);\n",
    "    iter_cnt = 0\n",
    "    while(True):\n",
    "        print('iteration {}'.format(iter_cnt).center(72, '-'))\n",
    "        pprint(prev_world)\n",
    "        if done(): break\n",
    "        prev_world = world.as_array()\n",
    "        pprint(prev_world)\n",
    "        for cell in world:\n",
    "            algo.update(cell)\n",
    "        iter_cnt += 1\n",
    "\n",
    "    world_arr = world.as_array()\n",
    "    pprint(world_arr)\n",
    "    pprint(np.round(world_arr))\n",
    "    pprint(world.policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def part_c():\n",
    "    global world, prev_world\n",
    "    discount_factor = 0.9\n",
    "    while(True):\n",
    "        world = GridWorld(world_input)\n",
    "        prev_world = np.ones_like(world_input) # init to something other than input\n",
    "        algo = ValueIterationAlgo(discount_factor, world)\n",
    "        iter_cnt = 0\n",
    "        while(True):\n",
    "            print ('iteration {}, discount={}'.format(\n",
    "                iter_cnt, discount_factor).center(72, '-'))\n",
    "            pprint(prev_world)\n",
    "            if done(): break\n",
    "            prev_world = world.as_array()\n",
    "            pprint(prev_world)\n",
    "            for cell in world:\n",
    "                algo.update(cell)\n",
    "            iter_cnt += 1\n",
    "        world_arr = world.as_array()\n",
    "        pprint(world_arr)\n",
    "        pprint(np.round(world_arr))\n",
    "        pprint(world.policy())\n",
    "        if world.cells[2][3].policy != 'west': break\n",
    "        discount_factor -= 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------iteration 0-------------------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "------------------------------iteration 1-------------------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.72      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4284    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.308448  ,  0.13208256]])\n",
      "------------------------------iteration 2-------------------------------\n",
      "array([[ 0.        ,  0.        ,  0.72      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4284    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.308448  ,  0.13208256]])\n",
      "array([[ 0.        ,  0.5184    ,  0.823356  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.54137232, -1.        ],\n",
      "       [ 0.        ,  0.22208256,  0.42166293,  0.22548474]])\n",
      "------------------------------iteration 3-------------------------------\n",
      "array([[ 0.        ,  0.5184    ,  0.823356  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.54137232, -1.        ],\n",
      "       [ 0.        ,  0.22208256,  0.42166293,  0.22548474]])\n",
      "array([[ 0.373248  ,  0.68612832,  0.84282555,  1.        ],\n",
      "       [ 0.26873856,         nan,  0.5655579 , -1.        ],\n",
      "       [ 0.21347919,  0.34357217,  0.45841681,  0.26035373]])\n",
      "------------------------------iteration 4-------------------------------\n",
      "array([[ 0.373248  ,  0.68612832,  0.84282555,  1.        ],\n",
      "       [ 0.26873856,         nan,  0.5655579 , -1.        ],\n",
      "       [ 0.21347919,  0.34357217,  0.45841681,  0.26035373]])\n",
      "array([[ 0.55179118,  0.73033749,  0.84675451,  1.        ],\n",
      "       [ 0.44566259,         nan,  0.57056346, -1.        ],\n",
      "       [ 0.37101169,  0.3919031 ,  0.46950881,  0.27147818]])\n",
      "------------------------------iteration 5-------------------------------\n",
      "array([[ 0.55179118,  0.73033749,  0.84675451,  1.        ],\n",
      "       [ 0.44566259,         nan,  0.57056346, -1.        ],\n",
      "       [ 0.37101169,  0.3919031 ,  0.46950881,  0.27147818]])\n",
      "array([[ 0.61561383,  0.741124  ,  0.84755862,  1.        ],\n",
      "       [ 0.52346123,         nan,  0.57159292, -1.        ],\n",
      "       [ 0.44555441,  0.4085889 ,  0.47275294,  0.27481515]])\n",
      "------------------------------iteration 6-------------------------------\n",
      "array([[ 0.61561383,  0.741124  ,  0.84755862,  1.        ],\n",
      "       [ 0.52346123,         nan,  0.57159292, -1.        ],\n",
      "       [ 0.44555441,  0.4085889 ,  0.47275294,  0.27481515]])\n",
      "array([[ 0.63612603,  0.74364452,  0.84772364,  1.        ],\n",
      "       [ 0.55223376,         nan,  0.57180438, -1.        ],\n",
      "       [ 0.47448121,  0.41517247,  0.47379804,  0.27586795]])\n",
      "------------------------------iteration 7-------------------------------\n",
      "array([[ 0.63612603,  0.74364452,  0.84772364,  1.        ],\n",
      "       [ 0.55223376,         nan,  0.57180438, -1.        ],\n",
      "       [ 0.47448121,  0.41517247,  0.47379804,  0.27586795]])\n",
      "array([[ 0.64237644,  0.74421703,  0.84775752,  1.        ],\n",
      "       [ 0.56191311,         nan,  0.57184781, -1.        ],\n",
      "       [ 0.48464627,  0.42367636,  0.47468941,  0.27660449]])\n",
      "------------------------------iteration 8-------------------------------\n",
      "array([[ 0.64237644,  0.74421703,  0.84775752,  1.        ],\n",
      "       [ 0.56191311,         nan,  0.57184781, -1.        ],\n",
      "       [ 0.48464627,  0.42367636,  0.47468941,  0.27660449]])\n",
      "array([[ 0.64422232,  0.74434448,  0.84776448,  1.        ],\n",
      "       [ 0.56498443,         nan,  0.57185673, -1.        ],\n",
      "       [ 0.48853783,  0.42800898,  0.47515206,  0.27700389]])\n",
      "------------------------------iteration 9-------------------------------\n",
      "array([[ 0.64422232,  0.74434448,  0.84776448,  1.        ],\n",
      "       [ 0.56498443,         nan,  0.57185673, -1.        ],\n",
      "       [ 0.48853783,  0.42800898,  0.47515206,  0.27700389]])\n",
      "array([[ 0.64475664,  0.74437243,  0.84776591,  1.        ],\n",
      "       [ 0.56592198,         nan,  0.57185856, -1.        ],\n",
      "       [ 0.48995304,  0.4298078 ,  0.47535121,  0.27718322]])\n",
      "------------------------------iteration 10------------------------------\n",
      "array([[ 0.64475664,  0.74437243,  0.84776591,  1.        ],\n",
      "       [ 0.56592198,         nan,  0.57185856, -1.        ],\n",
      "       [ 0.48995304,  0.4298078 ,  0.47535121,  0.27718322]])\n",
      "array([[ 0.64490923,  0.74437849,  0.8477662 ,  1.        ],\n",
      "       [ 0.5662006 ,         nan,  0.57185894, -1.        ],\n",
      "       [ 0.49044291,  0.4304843 ,  0.47542851,  0.27725502]])\n",
      "------------------------------iteration 11------------------------------\n",
      "array([[ 0.64490923,  0.74437849,  0.8477662 ,  1.        ],\n",
      "       [ 0.5662006 ,         nan,  0.57185894, -1.        ],\n",
      "       [ 0.49044291,  0.4304843 ,  0.47542851,  0.27725502]])\n",
      "array([[ 0.6449524 ,  0.74437979,  0.84776626,  1.        ],\n",
      "       [ 0.56628183,         nan,  0.57185901, -1.        ],\n",
      "       [ 0.49060637,  0.43072376,  0.47545658,  0.27728169]])\n",
      "------------------------------iteration 12------------------------------\n",
      "array([[ 0.6449524 ,  0.74437979,  0.84776626,  1.        ],\n",
      "       [ 0.56628183,         nan,  0.57185901, -1.        ],\n",
      "       [ 0.49060637,  0.43072376,  0.47545658,  0.27728169]])\n",
      "array([[ 0.64496453,  0.74438007,  0.84776627,  1.        ],\n",
      "       [ 0.56630519,         nan,  0.57185903, -1.        ],\n",
      "       [ 0.49065945,  0.43080508,  0.47546631,  0.2772911 ]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  1.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'west', 'north', 'west']]\n",
      "Value iteration: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:103: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "print ('Value iteration:',part_b())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------iteration 0, discount=0.9------------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.9------------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.72      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4284    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.308448  ,  0.13208256]])\n",
      "-----------------------iteration 2, discount=0.9------------------------\n",
      "array([[ 0.        ,  0.        ,  0.72      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4284    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.308448  ,  0.13208256]])\n",
      "array([[ 0.        ,  0.5184    ,  0.823356  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.54137232, -1.        ],\n",
      "       [ 0.        ,  0.22208256,  0.42166293,  0.22548474]])\n",
      "-----------------------iteration 3, discount=0.9------------------------\n",
      "array([[ 0.        ,  0.5184    ,  0.823356  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.54137232, -1.        ],\n",
      "       [ 0.        ,  0.22208256,  0.42166293,  0.22548474]])\n",
      "array([[ 0.373248  ,  0.68612832,  0.84282555,  1.        ],\n",
      "       [ 0.26873856,         nan,  0.5655579 , -1.        ],\n",
      "       [ 0.21347919,  0.34357217,  0.45841681,  0.26035373]])\n",
      "-----------------------iteration 4, discount=0.9------------------------\n",
      "array([[ 0.373248  ,  0.68612832,  0.84282555,  1.        ],\n",
      "       [ 0.26873856,         nan,  0.5655579 , -1.        ],\n",
      "       [ 0.21347919,  0.34357217,  0.45841681,  0.26035373]])\n",
      "array([[ 0.55179118,  0.73033749,  0.84675451,  1.        ],\n",
      "       [ 0.44566259,         nan,  0.57056346, -1.        ],\n",
      "       [ 0.37101169,  0.3919031 ,  0.46950881,  0.27147818]])\n",
      "-----------------------iteration 5, discount=0.9------------------------\n",
      "array([[ 0.55179118,  0.73033749,  0.84675451,  1.        ],\n",
      "       [ 0.44566259,         nan,  0.57056346, -1.        ],\n",
      "       [ 0.37101169,  0.3919031 ,  0.46950881,  0.27147818]])\n",
      "array([[ 0.61561383,  0.741124  ,  0.84755862,  1.        ],\n",
      "       [ 0.52346123,         nan,  0.57159292, -1.        ],\n",
      "       [ 0.44555441,  0.4085889 ,  0.47275294,  0.27481515]])\n",
      "-----------------------iteration 6, discount=0.9------------------------\n",
      "array([[ 0.61561383,  0.741124  ,  0.84755862,  1.        ],\n",
      "       [ 0.52346123,         nan,  0.57159292, -1.        ],\n",
      "       [ 0.44555441,  0.4085889 ,  0.47275294,  0.27481515]])\n",
      "array([[ 0.63612603,  0.74364452,  0.84772364,  1.        ],\n",
      "       [ 0.55223376,         nan,  0.57180438, -1.        ],\n",
      "       [ 0.47448121,  0.41517247,  0.47379804,  0.27586795]])\n",
      "-----------------------iteration 7, discount=0.9------------------------\n",
      "array([[ 0.63612603,  0.74364452,  0.84772364,  1.        ],\n",
      "       [ 0.55223376,         nan,  0.57180438, -1.        ],\n",
      "       [ 0.47448121,  0.41517247,  0.47379804,  0.27586795]])\n",
      "array([[ 0.64237644,  0.74421703,  0.84775752,  1.        ],\n",
      "       [ 0.56191311,         nan,  0.57184781, -1.        ],\n",
      "       [ 0.48464627,  0.42367636,  0.47468941,  0.27660449]])\n",
      "-----------------------iteration 8, discount=0.9------------------------\n",
      "array([[ 0.64237644,  0.74421703,  0.84775752,  1.        ],\n",
      "       [ 0.56191311,         nan,  0.57184781, -1.        ],\n",
      "       [ 0.48464627,  0.42367636,  0.47468941,  0.27660449]])\n",
      "array([[ 0.64422232,  0.74434448,  0.84776448,  1.        ],\n",
      "       [ 0.56498443,         nan,  0.57185673, -1.        ],\n",
      "       [ 0.48853783,  0.42800898,  0.47515206,  0.27700389]])\n",
      "-----------------------iteration 9, discount=0.9------------------------\n",
      "array([[ 0.64422232,  0.74434448,  0.84776448,  1.        ],\n",
      "       [ 0.56498443,         nan,  0.57185673, -1.        ],\n",
      "       [ 0.48853783,  0.42800898,  0.47515206,  0.27700389]])\n",
      "array([[ 0.64475664,  0.74437243,  0.84776591,  1.        ],\n",
      "       [ 0.56592198,         nan,  0.57185856, -1.        ],\n",
      "       [ 0.48995304,  0.4298078 ,  0.47535121,  0.27718322]])\n",
      "-----------------------iteration 10, discount=0.9-----------------------\n",
      "array([[ 0.64475664,  0.74437243,  0.84776591,  1.        ],\n",
      "       [ 0.56592198,         nan,  0.57185856, -1.        ],\n",
      "       [ 0.48995304,  0.4298078 ,  0.47535121,  0.27718322]])\n",
      "array([[ 0.64490923,  0.74437849,  0.8477662 ,  1.        ],\n",
      "       [ 0.5662006 ,         nan,  0.57185894, -1.        ],\n",
      "       [ 0.49044291,  0.4304843 ,  0.47542851,  0.27725502]])\n",
      "-----------------------iteration 11, discount=0.9-----------------------\n",
      "array([[ 0.64490923,  0.74437849,  0.8477662 ,  1.        ],\n",
      "       [ 0.5662006 ,         nan,  0.57185894, -1.        ],\n",
      "       [ 0.49044291,  0.4304843 ,  0.47542851,  0.27725502]])\n",
      "array([[ 0.6449524 ,  0.74437979,  0.84776626,  1.        ],\n",
      "       [ 0.56628183,         nan,  0.57185901, -1.        ],\n",
      "       [ 0.49060637,  0.43072376,  0.47545658,  0.27728169]])\n",
      "-----------------------iteration 12, discount=0.9-----------------------\n",
      "array([[ 0.6449524 ,  0.74437979,  0.84776626,  1.        ],\n",
      "       [ 0.56628183,         nan,  0.57185901, -1.        ],\n",
      "       [ 0.49060637,  0.43072376,  0.47545658,  0.27728169]])\n",
      "array([[ 0.64496453,  0.74438007,  0.84776627,  1.        ],\n",
      "       [ 0.56630519,         nan,  0.57185903, -1.        ],\n",
      "       [ 0.49065945,  0.43080508,  0.47546631,  0.2772911 ]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  1.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'west', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.89-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.89-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.712     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.417944  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.29757613,  0.1228742 ]])\n",
      "-----------------------iteration 2, discount=0.89-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.712     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.417944  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.29757613,  0.1228742 ]])\n",
      "array([[ 0.        ,  0.506944  ,  0.81256502,  1.        ],\n",
      "       [ 0.        ,         nan,  0.52674331, -1.        ],\n",
      "       [ 0.        ,  0.2118742 ,  0.40483384,  0.2101775 ]])\n",
      "-----------------------iteration 3, discount=0.89-----------------------\n",
      "array([[ 0.        ,  0.506944  ,  0.81256502,  1.        ],\n",
      "       [ 0.        ,         nan,  0.52674331, -1.        ],\n",
      "       [ 0.        ,  0.2118742 ,  0.40483384,  0.2101775 ]])\n",
      "array([[ 0.36094413,  0.66878232,  0.83119844,  1.        ],\n",
      "       [ 0.25699222,         nan,  0.54969344, -1.        ],\n",
      "       [ 0.20183526,  0.3259553 ,  0.43909755,  0.24234325]])\n",
      "-----------------------iteration 4, discount=0.89-----------------------\n",
      "array([[ 0.36094413,  0.66878232,  0.83119844,  1.        ],\n",
      "       [ 0.25699222,         nan,  0.54969344, -1.        ],\n",
      "       [ 0.20183526,  0.3259553 ,  0.43909755,  0.24234325]])\n",
      "array([[ 0.53116935,  0.71085654,  0.83489938,  1.        ],\n",
      "       [ 0.42393719,         nan,  0.55437107, -1.        ],\n",
      "       [ 0.34881664,  0.3706575 ,  0.44926927,  0.25244827]])\n",
      "-----------------------iteration 5, discount=0.89-----------------------\n",
      "array([[ 0.53116935,  0.71085654,  0.83489938,  1.        ],\n",
      "       [ 0.42393719,         nan,  0.55437107, -1.        ],\n",
      "       [ 0.34881664,  0.3706575 ,  0.44926927,  0.25244827]])\n",
      "array([[ 0.59113434,  0.72098082,  0.83564507,  1.        ],\n",
      "       [ 0.49634847,         nan,  0.55531832, -1.        ],\n",
      "       [ 0.41743331,  0.38585676,  0.45219579,  0.2554313 ]])\n",
      "-----------------------iteration 6, discount=0.89-----------------------\n",
      "array([[ 0.59113434,  0.72098082,  0.83564507,  1.        ],\n",
      "       [ 0.49634847,         nan,  0.55531832, -1.        ],\n",
      "       [ 0.41743331,  0.38585676,  0.45219579,  0.2554313 ]])\n",
      "array([[ 0.61012432,  0.72331388,  0.83579574,  1.        ],\n",
      "       [ 0.52275854,         nan,  0.5555099 , -1.        ],\n",
      "       [ 0.4436969 ,  0.3906459 ,  0.45302392,  0.25628642]])\n",
      "-----------------------iteration 7, discount=0.89-----------------------\n",
      "array([[ 0.61012432,  0.72331388,  0.83579574,  1.        ],\n",
      "       [ 0.52275854,         nan,  0.5555099 , -1.        ],\n",
      "       [ 0.4436969 ,  0.3906459 ,  0.45302392,  0.25628642]])\n",
      "array([[ 0.61582605,  0.72383644,  0.8358262 ,  1.        ],\n",
      "       [ 0.53151917,         nan,  0.55554864, -1.        ],\n",
      "       [ 0.45269816,  0.392088  ,  0.45325595,  0.25652773]])\n",
      "-----------------------iteration 8, discount=0.89-----------------------\n",
      "array([[ 0.61582605,  0.72383644,  0.8358262 ,  1.        ],\n",
      "       [ 0.53151917,         nan,  0.55554864, -1.        ],\n",
      "       [ 0.45269816,  0.392088  ,  0.45325595,  0.25652773]])\n",
      "array([[ 0.61748527,  0.72395114,  0.83583236,  1.        ],\n",
      "       [ 0.53425992,         nan,  0.55555647, -1.        ],\n",
      "       [ 0.45557903,  0.39416394,  0.45346776,  0.25670002]])\n",
      "-----------------------iteration 9, discount=0.89-----------------------\n",
      "array([[ 0.61748527,  0.72395114,  0.83583236,  1.        ],\n",
      "       [ 0.53425992,         nan,  0.55555647, -1.        ],\n",
      "       [ 0.45557903,  0.39416394,  0.45346776,  0.25670002]])\n",
      "array([[ 0.61795853,  0.72397594,  0.83583361,  1.        ],\n",
      "       [ 0.53508474,         nan,  0.55555805, -1.        ],\n",
      "       [ 0.45660746,  0.39526569,  0.45358228,  0.25679689]])\n",
      "----------------------iteration 10, discount=0.89-----------------------\n",
      "array([[ 0.61795853,  0.72397594,  0.83583361,  1.        ],\n",
      "       [ 0.53508474,         nan,  0.55555805, -1.        ],\n",
      "       [ 0.45660746,  0.39526569,  0.45358228,  0.25679689]])\n",
      "array([[ 0.61809172,  0.72398125,  0.83583386,  1.        ],\n",
      "       [ 0.53532639,         nan,  0.55555837, -1.        ],\n",
      "       [ 0.4569691 ,  0.39571929,  0.4536315 ,  0.25684055]])\n",
      "----------------------iteration 11, discount=0.89-----------------------\n",
      "array([[ 0.61809172,  0.72398125,  0.83583386,  1.        ],\n",
      "       [ 0.53532639,         nan,  0.55555837, -1.        ],\n",
      "       [ 0.4569691 ,  0.39571929,  0.4536315 ,  0.25684055]])\n",
      "array([[ 0.61812886,  0.72398237,  0.83583391,  1.        ],\n",
      "       [ 0.53539585,         nan,  0.55555844, -1.        ],\n",
      "       [ 0.45709111,  0.3958869 ,  0.45365035,  0.25685786]])\n",
      "----------------------iteration 12, discount=0.89-----------------------\n",
      "array([[ 0.61812886,  0.72398237,  0.83583391,  1.        ],\n",
      "       [ 0.53539585,         nan,  0.55555844, -1.        ],\n",
      "       [ 0.45709111,  0.3958869 ,  0.45365035,  0.25685786]])\n",
      "array([[ 0.61813914,  0.7239826 ,  0.83583392,  1.        ],\n",
      "       [ 0.53541553,         nan,  0.55555845, -1.        ],\n",
      "       [ 0.4571309 ,  0.39594507,  0.45365708,  0.25686419]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  1.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'west', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.88-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.88-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.704     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.407616  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.28696166,  0.11402101]])\n",
      "-----------------------iteration 2, discount=0.88-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.704     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.407616  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.28696166,  0.11402101]])\n",
      "array([[ 0.        ,  0.495616  ,  0.80182221,  1.        ],\n",
      "       [ 0.        ,         nan,  0.51235304, -1.        ],\n",
      "       [ 0.        ,  0.20202101,  0.38850824,  0.19554365]])\n",
      "-----------------------iteration 3, discount=0.88-----------------------\n",
      "array([[ 0.        ,  0.495616  ,  0.80182221,  1.        ],\n",
      "       [ 0.        ,         nan,  0.51235304, -1.        ],\n",
      "       [ 0.        ,  0.20202101,  0.38850824,  0.19554365]])\n",
      "array([[ 0.34891366,  0.65171125,  0.81964742,  1.        ],\n",
      "       [ 0.24563522,         nan,  0.53411885, -1.        ],\n",
      "       [ 0.19070504,  0.3090655 ,  0.42042528,  0.22518724]])\n",
      "-----------------------iteration 4, discount=0.88-----------------------\n",
      "array([[ 0.34891366,  0.65171125,  0.81964742,  1.        ],\n",
      "       [ 0.24563522,         nan,  0.53411885, -1.        ],\n",
      "       [ 0.19070504,  0.3090655 ,  0.42042528,  0.22518724]])\n",
      "array([[ 0.51112502,  0.69173297,  0.82313143,  1.        ],\n",
      "       [ 0.40306381,         nan,  0.53848699, -1.        ],\n",
      "       [ 0.32773673,  0.35037492,  0.42974431,  0.23435647]])\n",
      "-----------------------iteration 5, discount=0.88-----------------------\n",
      "array([[ 0.51112502,  0.69173297,  0.82313143,  1.        ],\n",
      "       [ 0.40306381,         nan,  0.53848699, -1.        ],\n",
      "       [ 0.32773673,  0.35037492,  0.42974431,  0.23435647]])\n",
      "array([[ 0.56742863,  0.70122953,  0.82382242,  1.        ],\n",
      "       [ 0.47040898,         nan,  0.53935784, -1.        ],\n",
      "       [ 0.39084175,  0.36420598,  0.43238141,  0.23701989]])\n",
      "-----------------------iteration 6, discount=0.88-----------------------\n",
      "array([[ 0.56742863,  0.70122953,  0.82382242,  1.        ],\n",
      "       [ 0.47040898,         nan,  0.53935784, -1.        ],\n",
      "       [ 0.39084175,  0.36420598,  0.43238141,  0.23701989]])\n",
      "array([[ 0.5849953 ,  0.70338738,  0.82395986,  1.        ],\n",
      "       [ 0.49462867,         nan,  0.53953123, -1.        ],\n",
      "       [ 0.41466278,  0.36849677,  0.43311545,  0.23777103]])\n",
      "-----------------------iteration 7, discount=0.88-----------------------\n",
      "array([[ 0.5849953 ,  0.70338738,  0.82395986,  1.        ],\n",
      "       [ 0.49462867,         nan,  0.53953123, -1.        ],\n",
      "       [ 0.41466278,  0.36849677,  0.43311545,  0.23777103]])\n",
      "array([[ 0.59019163,  0.70386392,  0.82398722,  1.        ],\n",
      "       [ 0.50254955,         nan,  0.53956575, -1.        ],\n",
      "       [ 0.42271292,  0.36976871,  0.43331778,  0.23797957]])\n",
      "-----------------------iteration 8, discount=0.88-----------------------\n",
      "array([[ 0.59019163,  0.70386392,  0.82398722,  1.        ],\n",
      "       [ 0.50254955,         nan,  0.53956575, -1.        ],\n",
      "       [ 0.42271292,  0.36976871,  0.43331778,  0.23797957]])\n",
      "array([[ 0.59168143,  0.70396705,  0.82399266,  1.        ],\n",
      "       [ 0.50499244,         nan,  0.53957262, -1.        ],\n",
      "       [ 0.42525306,  0.37013501,  0.43337321,  0.23803694]])\n",
      "-----------------------iteration 9, discount=0.88-----------------------\n",
      "array([[ 0.59168143,  0.70396705,  0.82399266,  1.        ],\n",
      "       [ 0.50499244,         nan,  0.53957262, -1.        ],\n",
      "       [ 0.42525306,  0.37013501,  0.43337321,  0.23803694]])\n",
      "array([[ 0.5921001 ,  0.70398903,  0.82399374,  1.        ],\n",
      "       [ 0.50571714,         nan,  0.53957399, -1.        ],\n",
      "       [ 0.42601902,  0.3702385 ,  0.43338833,  0.23805263]])\n",
      "----------------------iteration 10, discount=0.88-----------------------\n",
      "array([[ 0.5921001 ,  0.70398903,  0.82399374,  1.        ],\n",
      "       [ 0.50571714,         nan,  0.53957399, -1.        ],\n",
      "       [ 0.42601902,  0.3702385 ,  0.43338833,  0.23805263]])\n",
      "array([[ 0.5922162 ,  0.70399367,  0.82399396,  1.        ],\n",
      "       [ 0.50592642,         nan,  0.53957426, -1.        ],\n",
      "       [ 0.42624286,  0.37026736,  0.43339244,  0.23805691]])\n",
      "----------------------iteration 11, discount=0.88-----------------------\n",
      "array([[ 0.5922162 ,  0.70399367,  0.82399396,  1.        ],\n",
      "       [ 0.50592642,         nan,  0.53957426, -1.        ],\n",
      "       [ 0.42624286,  0.37026736,  0.43339244,  0.23805691]])\n",
      "array([[ 0.59224809,  0.70399463,  0.823994  ,  1.        ],\n",
      "       [ 0.50598571,         nan,  0.53957431, -1.        ],\n",
      "       [ 0.42630684,  0.37027533,  0.43339355,  0.23805807]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  1.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.87-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.87-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.696     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.397416  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.27660154,  0.10551467]])\n",
      "-----------------------iteration 2, discount=0.87-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.696     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.397416  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.27660154,  0.10551467]])\n",
      "array([[ 0.        ,  0.484416  ,  0.79112719,  1.        ],\n",
      "       [ 0.        ,         nan,  0.49819972, -1.        ],\n",
      "       [ 0.        ,  0.19251467,  0.37267556,  0.18156196]])\n",
      "-----------------------iteration 3, discount=0.87-----------------------\n",
      "array([[ 0.        ,  0.484416  ,  0.79112719,  1.        ],\n",
      "       [ 0.        ,         nan,  0.49819972, -1.        ],\n",
      "       [ 0.        ,  0.19251467,  0.37267556,  0.18156196]])\n",
      "array([[ 0.33715354,  0.63491291,  0.80817144,  1.        ],\n",
      "       [ 0.23465886,         nan,  0.5188307 , -1.        ],\n",
      "       [ 0.18007134,  0.29287974,  0.40238259,  0.20885418]])\n",
      "-----------------------iteration 4, discount=0.87-----------------------\n",
      "array([[ 0.33715354,  0.63491291,  0.80817144,  1.        ],\n",
      "       [ 0.23465886,         nan,  0.5188307 , -1.        ],\n",
      "       [ 0.18007134,  0.29287974,  0.40238259,  0.20885418]])\n",
      "array([[ 0.49164706,  0.67296217,  0.81144919,  1.        ],\n",
      "       [ 0.383017  ,         nan,  0.5229069 , -1.        ],\n",
      "       [ 0.30772657,  0.33101936,  0.4109122 ,  0.21716521]])\n",
      "-----------------------iteration 5, discount=0.87-----------------------\n",
      "array([[ 0.49164706,  0.67296217,  0.81144919,  1.        ],\n",
      "       [ 0.383017  ,         nan,  0.5229069 , -1.        ],\n",
      "       [ 0.30772657,  0.33101936,  0.4109122 ,  0.21716521]])\n",
      "array([[ 0.54447744,  0.68186405,  0.81208898,  1.        ],\n",
      "       [ 0.44560126,         nan,  0.52370683, -1.        ],\n",
      "       [ 0.36570937,  0.34359226,  0.41328585,  0.21954033]])\n",
      "-----------------------iteration 6, discount=0.87-----------------------\n",
      "array([[ 0.54447744,  0.68186405,  0.81208898,  1.        ],\n",
      "       [ 0.44560126,         nan,  0.52370683, -1.        ],\n",
      "       [ 0.36570937,  0.34359226,  0.41328585,  0.21954033]])\n",
      "array([[ 0.56071423,  0.68385827,  0.81221424,  1.        ],\n",
      "       [ 0.46779172,         nan,  0.5238636 , -1.        ],\n",
      "       [ 0.38729228,  0.34743201,  0.41393566,  0.22019923]])\n",
      "-----------------------iteration 7, discount=0.87-----------------------\n",
      "array([[ 0.56071423,  0.68385827,  0.81221424,  1.        ],\n",
      "       [ 0.46779172,         nan,  0.5238636 , -1.        ],\n",
      "       [ 0.38729228,  0.34743201,  0.41393566,  0.22019923]])\n",
      "array([[ 0.56544538,  0.68429245,  0.81223877,  1.        ],\n",
      "       [ 0.47494574,         nan,  0.52389432, -1.        ],\n",
      "       [ 0.39448325,  0.34855239,  0.41411184,  0.22037917]])\n",
      "-----------------------iteration 8, discount=0.87-----------------------\n",
      "array([[ 0.56544538,  0.68429245,  0.81223877,  1.        ],\n",
      "       [ 0.47494574,         nan,  0.52389432, -1.        ],\n",
      "       [ 0.39448325,  0.34855239,  0.41411184,  0.22037917]])\n",
      "array([[ 0.56678157,  0.68438507,  0.81224358,  1.        ],\n",
      "       [ 0.47712053,         nan,  0.52390034, -1.        ],\n",
      "       [ 0.39671999,  0.34886995,  0.41415931,  0.22042787]])\n",
      "-----------------------iteration 9, discount=0.87-----------------------\n",
      "array([[ 0.56678157,  0.68438507,  0.81224358,  1.        ],\n",
      "       [ 0.47712053,         nan,  0.52390034, -1.        ],\n",
      "       [ 0.39671999,  0.34886995,  0.41415931,  0.22042787]])\n",
      "array([[ 0.56715149,  0.68440453,  0.81224452,  1.        ],\n",
      "       [ 0.47775641,         nan,  0.52390152, -1.        ],\n",
      "       [ 0.39738479,  0.34895825,  0.41417205,  0.22044097]])\n",
      "----------------------iteration 10, discount=0.87-----------------------\n",
      "array([[ 0.56715149,  0.68440453,  0.81224452,  1.        ],\n",
      "       [ 0.47775641,         nan,  0.52390152, -1.        ],\n",
      "       [ 0.39738479,  0.34895825,  0.41417205,  0.22044097]])\n",
      "array([[ 0.56725254,  0.68440858,  0.81224471,  1.        ],\n",
      "       [ 0.47793739,         nan,  0.52390175, -1.        ],\n",
      "       [ 0.39757626,  0.34898248,  0.41417546,  0.22044448]])\n",
      "----------------------iteration 11, discount=0.87-----------------------\n",
      "array([[ 0.56725254,  0.68440858,  0.81224471,  1.        ],\n",
      "       [ 0.47793739,         nan,  0.52390175, -1.        ],\n",
      "       [ 0.39757626,  0.34898248,  0.41417546,  0.22044448]])\n",
      "array([[ 0.56727989,  0.68440941,  0.81224474,  1.        ],\n",
      "       [ 0.47798791,         nan,  0.52390179, -1.        ],\n",
      "       [ 0.3976302 ,  0.34898907,  0.41417637,  0.22044542]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.86-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.86-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.688     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.387344  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.26649267,  0.09734696]])\n",
      "-----------------------iteration 2, discount=0.86-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.688     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.387344  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.26649267,  0.09734696]])\n",
      "array([[ 0.        ,  0.473344  ,  0.78047958,  1.        ],\n",
      "       [ 0.        ,         nan,  0.48428154, -1.        ],\n",
      "       [ 0.        ,  0.18334696,  0.35732537,  0.1682117 ]])\n",
      "-----------------------iteration 3, discount=0.86-----------------------\n",
      "array([[ 0.        ,  0.473344  ,  0.78047958,  1.        ],\n",
      "       [ 0.        ,         nan,  0.48428154, -1.        ],\n",
      "       [ 0.        ,  0.18334696,  0.35732537,  0.1682117 ]])\n",
      "array([[ 0.32566067,  0.61838512,  0.79676946,  1.        ],\n",
      "       [ 0.22405454,         nan,  0.5038256 , -1.        ],\n",
      "       [ 0.16991736,  0.27737553,  0.38495251,  0.19331354]])\n",
      "-----------------------iteration 4, discount=0.86-----------------------\n",
      "array([[ 0.32566067,  0.61838512,  0.79676946,  1.        ],\n",
      "       [ 0.22405454,         nan,  0.5038256 , -1.        ],\n",
      "       [ 0.16991736,  0.27737553,  0.38495251,  0.19331354]])\n",
      "array([[ 0.47272447,  0.65453963,  0.79985117,  1.        ],\n",
      "       [ 0.36377182,         nan,  0.50762661, -1.        ],\n",
      "       [ 0.2887422 ,  0.31255592,  0.39275188,  0.20083826]])\n",
      "-----------------------iteration 5, discount=0.86-----------------------\n",
      "array([[ 0.47272447,  0.65453963,  0.79985117,  1.        ],\n",
      "       [ 0.36377182,         nan,  0.50762661, -1.        ],\n",
      "       [ 0.2887422 ,  0.31255592,  0.39275188,  0.20083826]])\n",
      "array([[ 0.52226194,  0.66287842,  0.80044309,  1.        ],\n",
      "       [ 0.42188497,         nan,  0.50836073, -1.        ],\n",
      "       [ 0.3419685 ,  0.32397291,  0.39488595,  0.20295362]])\n",
      "-----------------------iteration 6, discount=0.86-----------------------\n",
      "array([[ 0.52226194,  0.66287842,  0.80044309,  1.        ],\n",
      "       [ 0.42188497,         nan,  0.50836073, -1.        ],\n",
      "       [ 0.3419685 ,  0.32397291,  0.39488595,  0.20295362]])\n",
      "array([[ 0.53725699,  0.66471993,  0.80055713,  1.        ],\n",
      "       [ 0.44219702,         nan,  0.50850233, -1.        ],\n",
      "       [ 0.36150251,  0.32740487,  0.39546043,  0.20353079]])\n",
      "-----------------------iteration 7, discount=0.86-----------------------\n",
      "array([[ 0.53725699,  0.66471993,  0.80055713,  1.        ],\n",
      "       [ 0.44219702,         nan,  0.50850233, -1.        ],\n",
      "       [ 0.36150251,  0.32740487,  0.39546043,  0.20353079]])\n",
      "array([[ 0.54156036,  0.66511513,  0.80057911,  1.        ],\n",
      "       [ 0.44865142,         nan,  0.50852963, -1.        ],\n",
      "       [ 0.36791821,  0.32839041,  0.39561361,  0.20368581]])\n",
      "-----------------------iteration 8, discount=0.86-----------------------\n",
      "array([[ 0.54156036,  0.66511513,  0.80057911,  1.        ],\n",
      "       [ 0.44865142,         nan,  0.50852963, -1.        ],\n",
      "       [ 0.36791821,  0.32839041,  0.39561361,  0.20368581]])\n",
      "array([[ 0.54275742,  0.66519823,  0.80058335,  1.        ],\n",
      "       [ 0.45058515,         nan,  0.50853489, -1.        ],\n",
      "       [ 0.36988513,  0.32866531,  0.3956542 ,  0.20372707]])\n",
      "-----------------------iteration 9, discount=0.86-----------------------\n",
      "array([[ 0.54275742,  0.66519823,  0.80058335,  1.        ],\n",
      "       [ 0.45058515,         nan,  0.50853489, -1.        ],\n",
      "       [ 0.36988513,  0.32866531,  0.3956542 ,  0.20372707]])\n",
      "array([[ 0.54308385,  0.66521544,  0.80058417,  1.        ],\n",
      "       [ 0.45114233,         nan,  0.50853591, -1.        ],\n",
      "       [ 0.37046126,  0.32874053,  0.39566492,  0.20373799]])\n",
      "----------------------iteration 10, discount=0.86-----------------------\n",
      "array([[ 0.54308385,  0.66521544,  0.80058417,  1.        ],\n",
      "       [ 0.45114233,         nan,  0.50853591, -1.        ],\n",
      "       [ 0.37046126,  0.32874053,  0.39566492,  0.20373799]])\n",
      "array([[ 0.54317168,  0.66521896,  0.80058433,  1.        ],\n",
      "       [ 0.45129859,         nan,  0.50853611, -1.        ],\n",
      "       [ 0.37062479,  0.32876083,  0.39566774,  0.20374087]])\n",
      "----------------------iteration 11, discount=0.86-----------------------\n",
      "array([[ 0.54317168,  0.66521896,  0.80058433,  1.        ],\n",
      "       [ 0.45129859,         nan,  0.50853611, -1.        ],\n",
      "       [ 0.37062479,  0.32876083,  0.39566774,  0.20374087]])\n",
      "array([[ 0.54319509,  0.66521968,  0.80058436,  1.        ],\n",
      "       [ 0.45134158,         nan,  0.50853614, -1.        ],\n",
      "       [ 0.37067017,  0.32876627,  0.39566848,  0.20374163]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   1.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.85-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.85-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.68      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3774    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.256632  ,  0.08950976]])\n",
      "-----------------------iteration 2, discount=0.85-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.68      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3774    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.256632  ,  0.08950976]])\n",
      "array([[ 0.        ,  0.4624    ,  0.769879  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.47059672, -1.        ],\n",
      "       [ 0.        ,  0.17450976,  0.34244743,  0.15547258]])\n",
      "-----------------------iteration 3, discount=0.85-----------------------\n",
      "array([[ 0.        ,  0.4624    ,  0.769879  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.47059672, -1.        ],\n",
      "       [ 0.        ,  0.17450976,  0.34244743,  0.15547258]])\n",
      "array([[ 0.314432  ,  0.60212572,  0.78544044,  1.        ],\n",
      "       [ 0.21381376,         nan,  0.48910022, -1.        ],\n",
      "       [ 0.16022669,  0.26253091,  0.36811844,  0.17853571]])\n",
      "-----------------------iteration 4, discount=0.85-----------------------\n",
      "array([[ 0.314432  ,  0.60212572,  0.78544044,  1.        ],\n",
      "       [ 0.21381376,         nan,  0.48910022, -1.        ],\n",
      "       [ 0.16022669,  0.26253091,  0.36811844,  0.17853571]])\n",
      "array([[ 0.45434638,  0.63646087,  0.78833596,  1.        ],\n",
      "       [ 0.34530388,         nan,  0.49264197, -1.        ],\n",
      "       [ 0.27074103,  0.2949508 ,  0.37524289,  0.1853407 ]])\n",
      "-----------------------iteration 5, discount=0.85-----------------------\n",
      "array([[ 0.45434638,  0.63646087,  0.78833596,  1.        ],\n",
      "       [ 0.34530388,         nan,  0.49264197, -1.        ],\n",
      "       [ 0.27074103,  0.2949508 ,  0.37524289,  0.1853407 ]])\n",
      "array([[ 0.50076366,  0.6442668 ,  0.78888312,  1.        ],\n",
      "       [ 0.39922095,         nan,  0.49331509, -1.        ],\n",
      "       [ 0.31955405,  0.3053068 ,  0.3771593 ,  0.18722228]])\n",
      "-----------------------iteration 6, discount=0.85-----------------------\n",
      "array([[ 0.50076366,  0.6442668 ,  0.78888312,  1.        ],\n",
      "       [ 0.39922095,         nan,  0.49331509, -1.        ],\n",
      "       [ 0.31955405,  0.3053068 ,  0.3771593 ,  0.18722228]])\n",
      "array([[ 0.51460011,  0.64596588,  0.78898685,  1.        ],\n",
      "       [ 0.41779564,         nan,  0.49344284, -1.        ],\n",
      "       [ 0.33721421,  0.30837048,  0.37766652,  0.18772712]])\n",
      "-----------------------iteration 7, discount=0.85-----------------------\n",
      "array([[ 0.51460011,  0.64596588,  0.78898685,  1.        ],\n",
      "       [ 0.41779564,         nan,  0.49344284, -1.        ],\n",
      "       [ 0.33721421,  0.30837048,  0.37766652,  0.18772712]])\n",
      "array([[ 0.51851044,  0.64632526,  0.78900652,  1.        ],\n",
      "       [ 0.42361236,         nan,  0.49346708, -1.        ],\n",
      "       [ 0.3429311 ,  0.30923621,  0.3777995 ,  0.18786046]])\n",
      "-----------------------iteration 8, discount=0.85-----------------------\n",
      "array([[ 0.51851044,  0.64632526,  0.78900652,  1.        ],\n",
      "       [ 0.42361236,         nan,  0.49346708, -1.        ],\n",
      "       [ 0.3429311 ,  0.30923621,  0.3777995 ,  0.18786046]])\n",
      "array([[ 0.51958161,  0.64639973,  0.78901026,  1.        ],\n",
      "       [ 0.4253296 ,         nan,  0.49347168, -1.        ],\n",
      "       [ 0.34465835,  0.30947381,  0.37783415,  0.18789536]])\n",
      "-----------------------iteration 9, discount=0.85-----------------------\n",
      "array([[ 0.51958161,  0.64639973,  0.78901026,  1.        ],\n",
      "       [ 0.4253296 ,         nan,  0.49347168, -1.        ],\n",
      "       [ 0.34465835,  0.30947381,  0.37783415,  0.18789536]])\n",
      "array([[ 0.51986927,  0.64641493,  0.78901096,  1.        ],\n",
      "       [ 0.42581713,         nan,  0.49347255, -1.        ],\n",
      "       [ 0.34515688,  0.30953777,  0.37784315,  0.18790445]])\n",
      "----------------------iteration 10, discount=0.85-----------------------\n",
      "array([[ 0.51986927,  0.64641493,  0.78901096,  1.        ],\n",
      "       [ 0.42581713,         nan,  0.49347255, -1.        ],\n",
      "       [ 0.34515688,  0.30953777,  0.37784315,  0.18790445]])\n",
      "array([[ 0.5199455 ,  0.64641799,  0.7890111 ,  1.        ],\n",
      "       [ 0.42595185,         nan,  0.49347271, -1.        ],\n",
      "       [ 0.3452963 ,  0.30955476,  0.37784548,  0.1879068 ]])\n",
      "----------------------iteration 11, discount=0.85-----------------------\n",
      "array([[ 0.5199455 ,  0.64641799,  0.7890111 ,  1.        ],\n",
      "       [ 0.42595185,         nan,  0.49347271, -1.        ],\n",
      "       [ 0.3452963 ,  0.30955476,  0.37784548,  0.1879068 ]])\n",
      "array([[ 0.51996551,  0.64641861,  0.78901112,  1.        ],\n",
      "       [ 0.42598836,         nan,  0.49347274, -1.        ],\n",
      "       [ 0.34533443,  0.30955923,  0.37784608,  0.18790741]])\n",
      "array([[  1.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.84-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.84-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.672     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.367584  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.24701645,  0.08199505]])\n",
      "-----------------------iteration 2, discount=0.84-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.672     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.367584  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.24701645,  0.08199505]])\n",
      "array([[ 0.        ,  0.451584  ,  0.75932506,  1.        ],\n",
      "       [ 0.        ,         nan,  0.45714349, -1.        ],\n",
      "       [ 0.        ,  0.16599505,  0.3280316 ,  0.14332482]])\n",
      "-----------------------iteration 3, discount=0.84-----------------------\n",
      "array([[ 0.        ,  0.451584  ,  0.75932506,  1.        ],\n",
      "       [ 0.        ,         nan,  0.45714349, -1.        ],\n",
      "       [ 0.        ,  0.16599505,  0.3280316 ,  0.14332482]])\n",
      "array([[ 0.30346445,  0.58613255,  0.77418336,  1.        ],\n",
      "       [ 0.20392811,         nan,  0.47465127, -1.        ],\n",
      "       [ 0.15098327,  0.2483244 ,  0.35186419,  0.16449202]])\n",
      "-----------------------iteration 4, discount=0.84-----------------------\n",
      "array([[ 0.30346445,  0.58613255,  0.77418336,  1.        ],\n",
      "       [ 0.20392811,         nan,  0.47465127, -1.        ],\n",
      "       [ 0.15098327,  0.2483244 ,  0.35186419,  0.16449202]])\n",
      "array([[ 0.43650205,  0.61872149,  0.77690211,  1.        ],\n",
      "       [ 0.3275893 ,         nan,  0.47794892, -1.        ],\n",
      "       [ 0.25368185,  0.27817123,  0.35836539,  0.17063887]])\n",
      "-----------------------iteration 5, discount=0.84-----------------------\n",
      "array([[ 0.43650205,  0.61872149,  0.77690211,  1.        ],\n",
      "       [ 0.3275893 ,         nan,  0.47794892, -1.        ],\n",
      "       [ 0.25368185,  0.27817123,  0.35836539,  0.17063887]])\n",
      "array([[ 0.47996451,  0.62602343,  0.77740749,  1.        ],\n",
      "       [ 0.37757115,         nan,  0.47856554, -1.        ],\n",
      "       [ 0.29840347,  0.28755431,  0.36008427,  0.1723103 ]])\n",
      "-----------------------iteration 6, discount=0.84-----------------------\n",
      "array([[ 0.47996451,  0.62602343,  0.77740749,  1.        ],\n",
      "       [ 0.37757115,         nan,  0.47856554, -1.        ],\n",
      "       [ 0.29840347,  0.28755431,  0.36008427,  0.1723103 ]])\n",
      "array([[ 0.49272074,  0.62758977,  0.77750173,  1.        ],\n",
      "       [ 0.39454029,         nan,  0.47868067, -1.        ],\n",
      "       [ 0.31435153,  0.29028575,  0.36053148,  0.17275122]])\n",
      "-----------------------iteration 7, discount=0.84-----------------------\n",
      "array([[ 0.49272074,  0.62758977,  0.77750173,  1.        ],\n",
      "       [ 0.39454029,         nan,  0.47868067, -1.        ],\n",
      "       [ 0.31435153,  0.29028575,  0.36053148,  0.17275122]])\n",
      "array([[ 0.49627025,  0.62791625,  0.77751932,  1.        ],\n",
      "       [ 0.39977638,         nan,  0.47870216, -1.        ],\n",
      "       [ 0.31943926,  0.29104516,  0.36064675,  0.17286572]])\n",
      "-----------------------iteration 8, discount=0.84-----------------------\n",
      "array([[ 0.49627025,  0.62791625,  0.77751932,  1.        ],\n",
      "       [ 0.39977638,         nan,  0.47870216, -1.        ],\n",
      "       [ 0.31943926,  0.29104516,  0.36064675,  0.17286572]])\n",
      "array([[ 0.49722763,  0.62798291,  0.7775226 ,  1.        ],\n",
      "       [ 0.4012994 ,         nan,  0.47870617, -1.        ],\n",
      "       [ 0.32095389,  0.2912502 ,  0.36067628,  0.17289518]])\n",
      "-----------------------iteration 9, discount=0.84-----------------------\n",
      "array([[ 0.49722763,  0.62798291,  0.7775226 ,  1.        ],\n",
      "       [ 0.4012994 ,         nan,  0.47870617, -1.        ],\n",
      "       [ 0.32095389,  0.2912502 ,  0.36067628,  0.17289518]])\n",
      "array([[ 0.49748079,  0.62799632,  0.77752322,  1.        ],\n",
      "       [ 0.40172539,         nan,  0.47870692, -1.        ],\n",
      "       [ 0.32138461,  0.2913045 ,  0.36068382,  0.17290272]])\n",
      "----------------------iteration 10, discount=0.84-----------------------\n",
      "array([[ 0.49748079,  0.62799632,  0.77752322,  1.        ],\n",
      "       [ 0.40172539,         nan,  0.47870692, -1.        ],\n",
      "       [ 0.32138461,  0.2913045 ,  0.36068382,  0.17290272]])\n",
      "array([[ 0.49754685,  0.62799898,  0.77752333,  1.        ],\n",
      "       [ 0.40184135,         nan,  0.47870706, -1.        ],\n",
      "       [ 0.32150327,  0.29131869,  0.36068574,  0.17290465]])\n",
      "----------------------iteration 11, discount=0.84-----------------------\n",
      "array([[ 0.49754685,  0.62799898,  0.77752333,  1.        ],\n",
      "       [ 0.40184135,         nan,  0.47870706, -1.        ],\n",
      "       [ 0.32150327,  0.29131869,  0.36068574,  0.17290465]])\n",
      "array([[ 0.49756393,  0.62799951,  0.77752335,  1.        ],\n",
      "       [ 0.4018723 ,         nan,  0.47870709, -1.        ],\n",
      "       [ 0.32153523,  0.29132236,  0.36068623,  0.17290514]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.83-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.83-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.664     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.357896  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.23764294,  0.07479491]])\n",
      "-----------------------iteration 2, discount=0.83-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.664     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.357896  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.23764294,  0.07479491]])\n",
      "array([[ 0.        ,  0.440896  ,  0.74881737,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4439201 , -1.        ],\n",
      "       [ 0.        ,  0.15779491,  0.3140679 ,  0.13174907]])\n",
      "-----------------------iteration 3, discount=0.83-----------------------\n",
      "array([[ 0.        ,  0.440896  ,  0.74881737,  1.        ],\n",
      "       [ 0.        ,         nan,  0.4439201 , -1.        ],\n",
      "       [ 0.        ,  0.15779491,  0.3140679 ,  0.13174907]])\n",
      "array([[ 0.29275494,  0.57040347,  0.76299721,  1.        ],\n",
      "       [ 0.19438928,         nan,  0.46047552, -1.        ],\n",
      "       [ 0.14217146,  0.23473504,  0.33617392,  0.15115466]])\n",
      "-----------------------iteration 4, discount=0.83-----------------------\n",
      "array([[ 0.29275494,  0.57040347,  0.76299721,  1.        ],\n",
      "       [ 0.19438928,         nan,  0.46047552, -1.        ],\n",
      "       [ 0.14217146,  0.23473504,  0.33617392,  0.15115466]])\n",
      "array([[ 0.41918087,  0.60131712,  0.76554824,  1.        ],\n",
      "       [ 0.31060472,         nan,  0.4635435 , -1.        ],\n",
      "       [ 0.23752477,  0.2621855 ,  0.34210012,  0.15670031]])\n",
      "-----------------------iteration 5, discount=0.83-----------------------\n",
      "array([[ 0.41918087,  0.60131712,  0.76554824,  1.        ],\n",
      "       [ 0.31060472,         nan,  0.4635435 , -1.        ],\n",
      "       [ 0.23752477,  0.2621855 ,  0.34210012,  0.15670031]])\n",
      "array([[ 0.45984677,  0.60814267,  0.76601461,  1.        ],\n",
      "       [ 0.35689864,         nan,  0.46410781, -1.        ],\n",
      "       [ 0.27845665,  0.27067727,  0.34363993,  0.15818304]])\n",
      "-----------------------iteration 6, discount=0.83-----------------------\n",
      "array([[ 0.45984677,  0.60814267,  0.76601461,  1.        ],\n",
      "       [ 0.35689864,         nan,  0.46410781, -1.        ],\n",
      "       [ 0.27845665,  0.27067727,  0.34363993,  0.15818304]])\n",
      "array([[ 0.4715966 ,  0.60958539,  0.76610016,  1.        ],\n",
      "       [ 0.37238532,         nan,  0.46421146, -1.        ],\n",
      "       [ 0.29284197,  0.27310934,  0.34403367,  0.15856755]])\n",
      "-----------------------iteration 7, discount=0.83-----------------------\n",
      "array([[ 0.4715966 ,  0.60958539,  0.76610016,  1.        ],\n",
      "       [ 0.37238532,         nan,  0.46421146, -1.        ],\n",
      "       [ 0.29284197,  0.27310934,  0.34403367,  0.15856755]])\n",
      "array([[ 0.4748152 ,  0.60988168,  0.76611586,  1.        ],\n",
      "       [ 0.37709325,         nan,  0.46423048, -1.        ],\n",
      "       [ 0.29736388,  0.27377451,  0.34413343,  0.15866571]])\n",
      "-----------------------iteration 8, discount=0.83-----------------------\n",
      "array([[ 0.4748152 ,  0.60988168,  0.76611586,  1.        ],\n",
      "       [ 0.37709325,         nan,  0.46423048, -1.        ],\n",
      "       [ 0.29736388,  0.27377451,  0.34413343,  0.15866571]])\n",
      "array([[ 0.47566984,  0.60994129,  0.76611875,  1.        ],\n",
      "       [ 0.37844225,         nan,  0.46423398, -1.        ],\n",
      "       [ 0.29869014,  0.27395117,  0.34415856,  0.15869054]])\n",
      "-----------------------iteration 9, discount=0.83-----------------------\n",
      "array([[ 0.47566984,  0.60994129,  0.76611875,  1.        ],\n",
      "       [ 0.37844225,         nan,  0.46423398, -1.        ],\n",
      "       [ 0.29869014,  0.27395117,  0.34415856,  0.15869054]])\n",
      "array([[ 0.47589232,  0.6099531 ,  0.76611928,  1.        ],\n",
      "       [ 0.37881392,         nan,  0.46423462, -1.        ],\n",
      "       [ 0.29906167,  0.27399718,  0.34416487,  0.15869679]])\n",
      "----------------------iteration 10, discount=0.83-----------------------\n",
      "array([[ 0.47589232,  0.6099531 ,  0.76611928,  1.        ],\n",
      "       [ 0.37881392,         nan,  0.46423462, -1.        ],\n",
      "       [ 0.29906167,  0.27399718,  0.34416487,  0.15869679]])\n",
      "array([[ 0.47594948,  0.60995541,  0.76611937,  1.        ],\n",
      "       [ 0.37891356,         nan,  0.46423474, -1.        ],\n",
      "       [ 0.29916249,  0.274009  ,  0.34416645,  0.15869835]])\n",
      "----------------------iteration 11, discount=0.83-----------------------\n",
      "array([[ 0.47594948,  0.60995541,  0.76611937,  1.        ],\n",
      "       [ 0.37891356,         nan,  0.46423474, -1.        ],\n",
      "       [ 0.29916249,  0.274009  ,  0.34416645,  0.15869835]])\n",
      "array([[ 0.47596403,  0.60995586,  0.76611939,  1.        ],\n",
      "       [ 0.37893977,         nan,  0.46423476, -1.        ],\n",
      "       [ 0.29918924,  0.27401201,  0.34416684,  0.15869875]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "-----------------------iteration 0, discount=0.82-----------------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "-----------------------iteration 1, discount=0.82-----------------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.656     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.348336  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.22850842,  0.06790152]])\n",
      "-----------------------iteration 2, discount=0.82-----------------------\n",
      "array([[ 0.        ,  0.        ,  0.656     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.348336  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.22850842,  0.06790152]])\n",
      "array([[ 0.        ,  0.430336  ,  0.73835555,  1.        ],\n",
      "       [ 0.        ,         nan,  0.43092479, -1.        ],\n",
      "       [ 0.        ,  0.14990152,  0.30054651,  0.12072644]])\n",
      "-----------------------iteration 3, discount=0.82-----------------------\n",
      "array([[ 0.        ,  0.430336  ,  0.73835555,  1.        ],\n",
      "       [ 0.        ,         nan,  0.43092479, -1.        ],\n",
      "       [ 0.        ,  0.14990152,  0.30054651,  0.12072644]])\n",
      "array([[ 0.28230042,  0.55493635,  0.75188099,  1.        ],\n",
      "       [ 0.18518907,         nan,  0.44656976, -1.        ],\n",
      "       [ 0.13377596,  0.22174236,  0.32103221,  0.13849669]])\n",
      "-----------------------iteration 4, discount=0.82-----------------------\n",
      "array([[ 0.28230042,  0.55493635,  0.75188099,  1.        ],\n",
      "       [ 0.18518907,         nan,  0.44656976, -1.        ],\n",
      "       [ 0.13377596,  0.22174236,  0.32103221,  0.13849669]])\n",
      "array([[ 0.40237238,  0.58424349,  0.75427296,  1.        ],\n",
      "       [ 0.29432729,         nan,  0.44942178, -1.        ],\n",
      "       [ 0.2222312 ,  0.24696287,  0.32642837,  0.14349374]])\n",
      "-----------------------iteration 5, discount=0.82-----------------------\n",
      "array([[ 0.40237238,  0.58424349,  0.75427296,  1.        ],\n",
      "       [ 0.29432729,         nan,  0.44942178, -1.        ],\n",
      "       [ 0.2222312 ,  0.24696287,  0.32642837,  0.14349374]])\n",
      "array([[ 0.4403931 ,  0.59061899,  0.75470297,  1.        ],\n",
      "       [ 0.33716755,         nan,  0.44993773, -1.        ],\n",
      "       [ 0.25965583,  0.25463892,  0.32780603,  0.14480724]])\n",
      "-----------------------iteration 6, discount=0.82-----------------------\n",
      "array([[ 0.4403931 ,  0.59061899,  0.75470297,  1.        ],\n",
      "       [ 0.33716755,         nan,  0.44993773, -1.        ],\n",
      "       [ 0.25965583,  0.25463892,  0.32780603,  0.14480724]])\n",
      "array([[ 0.45120603,  0.59194666,  0.75478054,  1.        ],\n",
      "       [ 0.35128664,         nan,  0.45003093, -1.        ],\n",
      "       [ 0.2726162 ,  0.25680154,  0.32815221,  0.14514204]])\n",
      "-----------------------iteration 7, discount=0.82-----------------------\n",
      "array([[ 0.45120603,  0.59194666,  0.75478054,  1.        ],\n",
      "       [ 0.35128664,         nan,  0.45003093, -1.        ],\n",
      "       [ 0.2726162 ,  0.25680154,  0.32815221,  0.14514204]])\n",
      "array([[ 0.45412141,  0.59221529,  0.75479454,  1.        ],\n",
      "       [ 0.35551465,         nan,  0.45004775, -1.        ],\n",
      "       [ 0.27662987,  0.2573833 ,  0.32823841,  0.14522604]])\n",
      "-----------------------iteration 8, discount=0.82-----------------------\n",
      "array([[ 0.45412141,  0.59221529,  0.75479454,  1.        ],\n",
      "       [ 0.35551465,         nan,  0.45004775, -1.        ],\n",
      "       [ 0.27662987,  0.2573833 ,  0.32823841,  0.14522604]])\n",
      "array([[ 0.45488338,  0.59226853,  0.75479707,  1.        ],\n",
      "       [ 0.3567079 ,         nan,  0.45005079, -1.        ],\n",
      "       [ 0.27778946,  0.25753526,  0.32825975,  0.14524693]])\n",
      "-----------------------iteration 9, discount=0.82-----------------------\n",
      "array([[ 0.45488338,  0.59226853,  0.75479707,  1.        ],\n",
      "       [ 0.3567079 ,         nan,  0.45005079, -1.        ],\n",
      "       [ 0.27778946,  0.25753526,  0.32825975,  0.14524693]])\n",
      "array([[ 0.45507864,  0.59227891,  0.75479752,  1.        ],\n",
      "       [ 0.35703168,         nan,  0.45005134, -1.        ],\n",
      "       [ 0.27810941,  0.25757418,  0.32826501,  0.14525209]])\n",
      "----------------------iteration 10, discount=0.82-----------------------\n",
      "array([[ 0.45507864,  0.59227891,  0.75479752,  1.        ],\n",
      "       [ 0.35703168,         nan,  0.45005134, -1.        ],\n",
      "       [ 0.27810941,  0.25757418,  0.32826501,  0.14525209]])\n",
      "array([[ 0.45512801,  0.59228092,  0.75479761,  1.        ],\n",
      "       [ 0.35711717,         nan,  0.45005144, -1.        ],\n",
      "       [ 0.27819492,  0.25758401,  0.32826631,  0.14525337]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.8099999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.8099999999999999----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:103: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.648     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.338904  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.21960979,  0.06130715]])\n",
      "----------------iteration 2, discount=0.8099999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.648     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.338904  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.21960979,  0.06130715]])\n",
      "array([[ 0.        ,  0.419904  ,  0.72793922,  1.        ],\n",
      "       [ 0.        ,         nan,  0.41815584, -1.        ],\n",
      "       [ 0.        ,  0.14230715,  0.28745774,  0.1102385 ]])\n",
      "----------------iteration 3, discount=0.8099999999999999----------------\n",
      "array([[ 0.        ,  0.419904  ,  0.72793922,  1.        ],\n",
      "       [ 0.        ,         nan,  0.41815584, -1.        ],\n",
      "       [ 0.        ,  0.14230715,  0.28745774,  0.1102385 ]])\n",
      "array([[ 0.27209779,  0.53972907,  0.7408337 ,  1.        ],\n",
      "       [ 0.17631937,         nan,  0.43293086, -1.        ],\n",
      "       [ 0.12578183,  0.20932637,  0.30642395,  0.12649204]])\n",
      "----------------iteration 4, discount=0.8099999999999999----------------\n",
      "array([[ 0.27209779,  0.53972907,  0.7408337 ,  1.        ],\n",
      "       [ 0.17631937,         nan,  0.43293086, -1.        ],\n",
      "       [ 0.12578183,  0.20932637,  0.30642395,  0.12649204]])\n",
      "array([[ 0.38606622,  0.56749635,  0.74307493,  1.        ],\n",
      "       [ 0.27873465,         nan,  0.43557995, -1.        ],\n",
      "       [ 0.20776382,  0.23247359,  0.31133203,  0.13098901]])\n",
      "----------------iteration 5, discount=0.8099999999999999----------------\n",
      "array([[ 0.38606622,  0.56749635,  0.74307493,  1.        ],\n",
      "       [ 0.27873465,         nan,  0.43557995, -1.        ],\n",
      "       [ 0.20776382,  0.23247359,  0.31133203,  0.13098901]])\n",
      "array([[ 0.4215865 ,  0.57344696,  0.74347105,  1.        ],\n",
      "       [ 0.31834307,         nan,  0.43605121, -1.        ],\n",
      "       [ 0.24194554,  0.23940388,  0.31256301,  0.13215094]])\n",
      "----------------iteration 6, discount=0.8099999999999999----------------\n",
      "array([[ 0.4215865 ,  0.57344696,  0.74347105,  1.        ],\n",
      "       [ 0.31834307,         nan,  0.43605121, -1.        ],\n",
      "       [ 0.24194554,  0.23940388,  0.31256301,  0.13215094]])\n",
      "array([[ 0.43152793,  0.57466765,  0.7435413 ,  1.        ],\n",
      "       [ 0.33120167,         nan,  0.43613491, -1.        ],\n",
      "       [ 0.25360799,  0.24132426,  0.31286691,  0.13244199]])\n",
      "----------------iteration 7, discount=0.8099999999999999----------------\n",
      "array([[ 0.43152793,  0.57466765,  0.7435413 ,  1.        ],\n",
      "       [ 0.33120167,         nan,  0.43613491, -1.        ],\n",
      "       [ 0.25360799,  0.24132426,  0.31286691,  0.13244199]])\n",
      "array([[ 0.43416573,  0.57491092,  0.74355377,  1.        ],\n",
      "       [ 0.33499407,         nan,  0.43614977, -1.        ],\n",
      "       [ 0.25716567,  0.24183229,  0.31294127,  0.13251374]])\n",
      "----------------iteration 8, discount=0.8099999999999999----------------\n",
      "array([[ 0.43416573,  0.57491092,  0.74355377,  1.        ],\n",
      "       [ 0.33499407,         nan,  0.43614977, -1.        ],\n",
      "       [ 0.25716567,  0.24183229,  0.31294127,  0.13251374]])\n",
      "array([[ 0.43484422,  0.57495841,  0.74355599,  1.        ],\n",
      "       [ 0.33604809,         nan,  0.43615241, -1.        ],\n",
      "       [ 0.258178  ,  0.24196277,  0.31295936,  0.13253128]])\n",
      "----------------iteration 9, discount=0.8099999999999999----------------\n",
      "array([[ 0.43484422,  0.57495841,  0.74355599,  1.        ],\n",
      "       [ 0.33604809,         nan,  0.43615241, -1.        ],\n",
      "       [ 0.258178  ,  0.24196277,  0.31295936,  0.13253128]])\n",
      "array([[ 0.43501533,  0.57496754,  0.74355638,  1.        ],\n",
      "       [ 0.33632973,         nan,  0.43615288, -1.        ],\n",
      "       [ 0.25845306,  0.24199563,  0.31296375,  0.13253554]])\n",
      "---------------iteration 10, discount=0.8099999999999999----------------\n",
      "array([[ 0.43501533,  0.57496754,  0.74355638,  1.        ],\n",
      "       [ 0.33632973,         nan,  0.43615288, -1.        ],\n",
      "       [ 0.25845306,  0.24199563,  0.31296375,  0.13253554]])\n",
      "array([[ 0.43505792,  0.57496928,  0.74355645,  1.        ],\n",
      "       [ 0.33640295,         nan,  0.43615296, -1.        ],\n",
      "       [ 0.25852545,  0.2420038 ,  0.31296481,  0.13253657]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7999999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7999999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.64      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3296    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.210944  ,  0.05500416]])\n",
      "----------------iteration 2, discount=0.7999999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.64      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3296    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.210944  ,  0.05500416]])\n",
      "array([[ 0.        ,  0.4096    ,  0.717568  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.40561152, -1.        ],\n",
      "       [ 0.        ,  0.13500416,  0.27479204,  0.10026724]])\n",
      "----------------iteration 3, discount=0.7999999999999999----------------\n",
      "array([[ 0.        ,  0.4096    ,  0.717568  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.40561152, -1.        ],\n",
      "       [ 0.        ,  0.13500416,  0.27479204,  0.10026724]])\n",
      "array([[ 0.262144  ,  0.52477952,  0.72985436,  1.        ],\n",
      "       [ 0.16777216,         nan,  0.41955571, -1.        ],\n",
      "       [ 0.11817452,  0.19746757,  0.29233444,  0.11511542]])\n",
      "----------------iteration 4, discount=0.7999999999999999----------------\n",
      "array([[ 0.262144  ,  0.52477952,  0.72985436,  1.        ],\n",
      "       [ 0.16777216,         nan,  0.41955571, -1.        ],\n",
      "       [ 0.11817452,  0.19746757,  0.29233444,  0.11511542]])\n",
      "array([[ 0.37025219,  0.55107151,  0.73195281,  1.        ],\n",
      "       [ 0.26380494,         nan,  0.42201425, -1.        ],\n",
      "       [ 0.19408653,  0.21868885,  0.29679346,  0.11915705]])\n",
      "----------------iteration 5, discount=0.7999999999999999----------------\n",
      "array([[ 0.37025219,  0.55107151,  0.73195281,  1.        ],\n",
      "       [ 0.26380494,         nan,  0.42201425, -1.        ],\n",
      "       [ 0.19408653,  0.21868885,  0.29679346,  0.11915705]])\n",
      "array([[ 0.40341034,  0.55662124,  0.73231736,  1.        ],\n",
      "       [ 0.30039141,         nan,  0.42244425, -1.        ],\n",
      "       [ 0.22527253,  0.22493803,  0.29789193,  0.1201834 ]])\n",
      "----------------iteration 6, discount=0.7999999999999999----------------\n",
      "array([[ 0.40341034,  0.55662124,  0.73231736,  1.        ],\n",
      "       [ 0.30039141,         nan,  0.42244425, -1.        ],\n",
      "       [ 0.22527253,  0.22493803,  0.29789193,  0.1201834 ]])\n",
      "array([[ 0.41254173,  0.55774251,  0.73238093,  1.        ],\n",
      "       [ 0.31208933,         nan,  0.42251934, -1.        ],\n",
      "       [ 0.23575402,  0.22664092,  0.29815832,  0.120436  ]])\n",
      "----------------iteration 7, discount=0.7999999999999999----------------\n",
      "array([[ 0.41254173,  0.55774251,  0.73238093,  1.        ],\n",
      "       [ 0.31208933,         nan,  0.42251934, -1.        ],\n",
      "       [ 0.23575402,  0.22664092,  0.29815832,  0.120436  ]])\n",
      "array([[ 0.41492569,  0.5579626 ,  0.73239202,  1.        ],\n",
      "       [ 0.31548674,         nan,  0.42253244, -1.        ],\n",
      "       [ 0.23890311,  0.22708387,  0.29822235,  0.12049718]])\n",
      "----------------iteration 8, discount=0.7999999999999999----------------\n",
      "array([[ 0.41492569,  0.5579626 ,  0.73239202,  1.        ],\n",
      "       [ 0.31548674,         nan,  0.42253244, -1.        ],\n",
      "       [ 0.23890311,  0.22708387,  0.29822235,  0.12049718]])\n",
      "array([[ 0.41552906,  0.55800491,  0.73239396,  1.        ],\n",
      "       [ 0.31641647,         nan,  0.42253473, -1.        ],\n",
      "       [ 0.2397855 ,  0.22719572,  0.29823766,  0.12051188]])\n",
      "----------------iteration 9, discount=0.7999999999999999----------------\n",
      "array([[ 0.41552906,  0.55800491,  0.73239396,  1.        ],\n",
      "       [ 0.31641647,         nan,  0.42253473, -1.        ],\n",
      "       [ 0.2397855 ,  0.22719572,  0.29823766,  0.12051188]])\n",
      "array([[ 0.41567878,  0.55801292,  0.73239429,  1.        ],\n",
      "       [ 0.31666106,         nan,  0.42253513, -1.        ],\n",
      "       [ 0.24002158,  0.22722342,  0.2982413 ,  0.12051539]])\n",
      "---------------iteration 10, discount=0.7999999999999999----------------\n",
      "array([[ 0.41567878,  0.55801292,  0.73239429,  1.        ],\n",
      "       [ 0.31666106,         nan,  0.42253513, -1.        ],\n",
      "       [ 0.24002158,  0.22722342,  0.2982413 ,  0.12051539]])\n",
      "array([[ 0.41571545,  0.55801442,  0.73239435,  1.        ],\n",
      "       [ 0.31672366,         nan,  0.4225352 , -1.        ],\n",
      "       [ 0.24008274,  0.22723018,  0.29824217,  0.12051622]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7899999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7899999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.632     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.320424  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.20250797,  0.04898504]])\n",
      "----------------iteration 2, discount=0.7899999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.632     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.320424  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.20250797,  0.04898504]])\n",
      "array([[ 0.        ,  0.399424  ,  0.7072415 ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.39329012, -1.        ],\n",
      "       [ 0.        ,  0.12798504,  0.26253999,  0.09079509]])\n",
      "----------------iteration 3, discount=0.7899999999999999----------------\n",
      "array([[ 0.        ,  0.399424  ,  0.7072415 ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.39329012, -1.        ],\n",
      "       [ 0.        ,  0.12798504,  0.26253999,  0.09079509]])\n",
      "array([[ 0.25243597,  0.51008562,  0.718942  ,  1.        ],\n",
      "       [ 0.15953953,         nan,  0.40644126, -1.        ],\n",
      "       [ 0.1109398 ,  0.18614691,  0.2787493 ,  0.10434237]])\n",
      "----------------iteration 4, discount=0.7899999999999999----------------\n",
      "array([[ 0.25243597,  0.51008562,  0.718942  ,  1.        ],\n",
      "       [ 0.15953953,         nan,  0.40644126, -1.        ],\n",
      "       [ 0.1109398 ,  0.18614691,  0.2787493 ,  0.10434237]])\n",
      "array([[ 0.35492017,  0.53496487,  0.72090528,  1.        ],\n",
      "       [ 0.2495168 ,         nan,  0.408721  , -1.        ],\n",
      "       [ 0.18116447,  0.20558077,  0.2827956 ,  0.10796986]])\n",
      "----------------iteration 5, discount=0.7899999999999999----------------\n",
      "array([[ 0.35492017,  0.53496487,  0.72090528,  1.        ],\n",
      "       [ 0.2495168 ,         nan,  0.408721  , -1.        ],\n",
      "       [ 0.18116447,  0.20558077,  0.2827956 ,  0.10796986]])\n",
      "array([[ 0.38584832,  0.54013658,  0.72124048,  1.        ],\n",
      "       [ 0.28327979,         nan,  0.40911294, -1.        ],\n",
      "       [ 0.2095857 ,  0.21120858,  0.28377447,  0.10887509]])\n",
      "----------------iteration 6, discount=0.7899999999999999----------------\n",
      "array([[ 0.38584832,  0.54013658,  0.72124048,  1.        ],\n",
      "       [ 0.28327979,         nan,  0.40911294, -1.        ],\n",
      "       [ 0.2095857 ,  0.21120858,  0.28377447,  0.10887509]])\n",
      "array([[ 0.39422744,  0.54116556,  0.72129792,  1.        ],\n",
      "       [ 0.29390995,         nan,  0.40918021, -1.        ],\n",
      "       [ 0.21899384,  0.21271642,  0.28400762,  0.10909395]])\n",
      "----------------iteration 7, discount=0.7899999999999999----------------\n",
      "array([[ 0.39422744,  0.54116556,  0.72129792,  1.        ],\n",
      "       [ 0.29390995,         nan,  0.40918021, -1.        ],\n",
      "       [ 0.21899384,  0.21271642,  0.28400762,  0.10909395]])\n",
      "array([[ 0.39637949,  0.54136444,  0.72130777,  1.        ],\n",
      "       [ 0.29694961,         nan,  0.40919175, -1.        ],\n",
      "       [ 0.22177726,  0.21310201,  0.28406267,  0.10914603]])\n",
      "----------------iteration 8, discount=0.7899999999999999----------------\n",
      "array([[ 0.39637949,  0.54136444,  0.72130777,  1.        ],\n",
      "       [ 0.29694961,         nan,  0.40919175, -1.        ],\n",
      "       [ 0.22177726,  0.21310201,  0.28406267,  0.10914603]])\n",
      "array([[ 0.39691533,  0.54140209,  0.72130946,  1.        ],\n",
      "       [ 0.29776853,         nan,  0.40919373, -1.        ],\n",
      "       [ 0.22254517,  0.21319772,  0.28407559,  0.10915831]])\n",
      "----------------iteration 9, discount=0.7899999999999999----------------\n",
      "array([[ 0.39691533,  0.54140209,  0.72130946,  1.        ],\n",
      "       [ 0.29776853,         nan,  0.40919373, -1.        ],\n",
      "       [ 0.22254517,  0.21319772,  0.28407559,  0.10915831]])\n",
      "array([[ 0.39704615,  0.54140911,  0.72130975,  1.        ],\n",
      "       [ 0.29798059,         nan,  0.40919407, -1.        ],\n",
      "       [ 0.22274742,  0.21322101,  0.28407862,  0.10916119]])\n",
      "---------------iteration 10, discount=0.7899999999999999----------------\n",
      "array([[ 0.39704615,  0.54140911,  0.72130975,  1.        ],\n",
      "       [ 0.29798059,         nan,  0.40919407, -1.        ],\n",
      "       [ 0.22274742,  0.21322101,  0.28407862,  0.10916119]])\n",
      "array([[ 0.39707767,  0.5414104 ,  0.7213098 ,  1.        ],\n",
      "       [ 0.29803402,         nan,  0.40919413, -1.        ],\n",
      "       [ 0.22279901,  0.21322661,  0.28407932,  0.10916187]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7799999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7799999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.624     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.311376  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.19429862,  0.04324234]])\n",
      "----------------iteration 2, discount=0.7799999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.624     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.311376  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.19429862,  0.04324234]])\n",
      "array([[ 0.        ,  0.389376  ,  0.69695933,  1.        ],\n",
      "       [ 0.        ,         nan,  0.38118995, -1.        ],\n",
      "       [ 0.        ,  0.12124234,  0.25069233,  0.08180492]])\n",
      "----------------iteration 3, discount=0.7799999999999999----------------\n",
      "array([[ 0.        ,  0.389376  ,  0.69695933,  1.        ],\n",
      "       [ 0.        ,         nan,  0.38118995, -1.        ],\n",
      "       [ 0.        ,  0.12124234,  0.25069233,  0.08180492]])\n",
      "array([[ 0.24297062,  0.49564528,  0.70809564,  1.        ],\n",
      "       [ 0.15161367,         nan,  0.3935845 , -1.        ],\n",
      "       [ 0.10406383,  0.17534582,  0.26565448,  0.09414918]])\n",
      "----------------iteration 4, discount=0.7799999999999999----------------\n",
      "array([[ 0.24297062,  0.49564528,  0.70809564,  1.        ],\n",
      "       [ 0.15161367,         nan,  0.3935845 , -1.        ],\n",
      "       [ 0.10406383,  0.17534582,  0.26565448,  0.09414918]])\n",
      "array([[ 0.34006023,  0.51917234,  0.70993105,  1.        ],\n",
      "       [ 0.23584931,         nan,  0.39569657, -1.        ],\n",
      "       [ 0.16896393,  0.19312235,  0.26932184,  0.09740046]])\n",
      "----------------iteration 5, discount=0.7799999999999999----------------\n",
      "array([[ 0.34006023,  0.51917234,  0.70993105,  1.        ],\n",
      "       [ 0.23584931,         nan,  0.39569657, -1.        ],\n",
      "       [ 0.16896393,  0.19312235,  0.26932184,  0.09740046]])\n",
      "array([[ 0.36888449,  0.52398786,  0.71023895,  1.        ],\n",
      "       [ 0.26697641,         nan,  0.39605344, -1.        ],\n",
      "       [ 0.19483601,  0.19818391,  0.27019293,  0.09819762]])\n",
      "----------------iteration 6, discount=0.7799999999999999----------------\n",
      "array([[ 0.36888449,  0.52398786,  0.71023895,  1.        ],\n",
      "       [ 0.26697641,         nan,  0.39605344, -1.        ],\n",
      "       [ 0.19483601,  0.19818391,  0.27019293,  0.09819762]])\n",
      "array([[ 0.37656558,  0.52493121,  0.71029081,  1.        ],\n",
      "       [ 0.27662524,         nan,  0.39611363, -1.        ],\n",
      "       [ 0.2032697 ,  0.19951708,  0.27039665,  0.09838693]])\n",
      "----------------iteration 7, discount=0.7799999999999999----------------\n",
      "array([[ 0.37656558,  0.52493121,  0.71029081,  1.        ],\n",
      "       [ 0.27662524,         nan,  0.39611363, -1.        ],\n",
      "       [ 0.2032697 ,  0.19951708,  0.27039665,  0.09838693]])\n",
      "array([[ 0.37850596,  0.52511073,  0.71029955,  1.        ],\n",
      "       [ 0.27934126,         nan,  0.39612378, -1.        ],\n",
      "       [ 0.20572631,  0.19985218,  0.27044389,  0.09843117]])\n",
      "----------------iteration 8, discount=0.7799999999999999----------------\n",
      "array([[ 0.37850596,  0.52511073,  0.71029955,  1.        ],\n",
      "       [ 0.27934126,         nan,  0.39612378, -1.        ],\n",
      "       [ 0.20572631,  0.19985218,  0.27044389,  0.09843117]])\n",
      "array([[ 0.37898118,  0.52514419,  0.71030102,  1.        ],\n",
      "       [ 0.28006149,         nan,  0.39612549, -1.        ],\n",
      "       [ 0.20639349,  0.19993393,  0.27045478,  0.09844142]])\n",
      "----------------iteration 9, discount=0.7799999999999999----------------\n",
      "array([[ 0.37898118,  0.52514419,  0.71030102,  1.        ],\n",
      "       [ 0.28006149,         nan,  0.39612549, -1.        ],\n",
      "       [ 0.20639349,  0.19993393,  0.27045478,  0.09844142]])\n",
      "array([[ 0.3790953 ,  0.52515033,  0.71030127,  1.        ],\n",
      "       [ 0.28024506,         nan,  0.39612578, -1.        ],\n",
      "       [ 0.20656646,  0.19995348,  0.27045729,  0.09844378]])\n",
      "---------------iteration 10, discount=0.7799999999999999----------------\n",
      "array([[ 0.3790953 ,  0.52515033,  0.71030127,  1.        ],\n",
      "       [ 0.28024506,         nan,  0.39612578, -1.        ],\n",
      "       [ 0.20656646,  0.19995348,  0.27045729,  0.09844378]])\n",
      "array([[ 0.37912235,  0.52515144,  0.71030131,  1.        ],\n",
      "       [ 0.28029058,         nan,  0.39612583, -1.        ],\n",
      "       [ 0.20660988,  0.19995809,  0.27045786,  0.09844432]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7699999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7699999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.616     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.302456  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.1863129 ,  0.03776874]])\n",
      "----------------iteration 2, discount=0.7699999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.616     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.302456  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.1863129 ,  0.03776874]])\n",
      "array([[ 0.        ,  0.379456  ,  0.68672111,  1.        ],\n",
      "       [ 0.        ,         nan,  0.36930932, -1.        ],\n",
      "       [ 0.        ,  0.11476874,  0.23923993,  0.07327999]])\n",
      "----------------iteration 3, discount=0.7699999999999999----------------\n",
      "array([[ 0.        ,  0.379456  ,  0.68672111,  1.        ],\n",
      "       [ 0.        ,         nan,  0.36930932, -1.        ],\n",
      "       [ 0.        ,  0.11476874,  0.23923993,  0.07327999]])\n",
      "array([[ 0.2337449 ,  0.48145643,  0.69731434,  1.        ],\n",
      "       [ 0.14398686,         nan,  0.38098245, -1.        ],\n",
      "       [ 0.0975331 ,  0.16504618,  0.25303631,  0.08451292]])\n",
      "----------------iteration 4, discount=0.7699999999999999----------------\n",
      "array([[ 0.2337449 ,  0.48145643,  0.69731434,  1.        ],\n",
      "       [ 0.14398686,         nan,  0.38098245, -1.        ],\n",
      "       [ 0.0975331 ,  0.16504618,  0.25303631,  0.08451292]])\n",
      "array([[ 0.32566251,  0.50368993,  0.69902885,  1.        ],\n",
      "       [ 0.22278208,         nan,  0.38293742, -1.        ],\n",
      "       [ 0.15745237,  0.18128748,  0.25635608,  0.08742284]])\n",
      "----------------iteration 5, discount=0.7699999999999999----------------\n",
      "array([[ 0.32566251,  0.50368993,  0.69902885,  1.        ],\n",
      "       [ 0.22278208,         nan,  0.38293742, -1.        ],\n",
      "       [ 0.15745237,  0.18128748,  0.25635608,  0.08742284]])\n",
      "array([[ 0.35250323,  0.50817002,  0.6993114 ,  1.        ],\n",
      "       [ 0.25145043,         nan,  0.38326201, -1.        ],\n",
      "       [ 0.18097643,  0.18583362,  0.25713014,  0.08812373]])\n",
      "----------------iteration 6, discount=0.7699999999999999----------------\n",
      "array([[ 0.35250323,  0.50817002,  0.6993114 ,  1.        ],\n",
      "       [ 0.25145043,         nan,  0.38326201, -1.        ],\n",
      "       [ 0.18097643,  0.18583362,  0.25713014,  0.08812373]])\n",
      "array([[ 0.35953717,  0.50903401,  0.69935815,  1.        ],\n",
      "       [ 0.26019826,         nan,  0.3833158 , -1.        ],\n",
      "       [ 0.1885265 ,  0.18701055,  0.25730787,  0.08828717]])\n",
      "----------------iteration 7, discount=0.7699999999999999----------------\n",
      "array([[ 0.35953717,  0.50903401,  0.69935815,  1.        ],\n",
      "       [ 0.26019826,         nan,  0.3833158 , -1.        ],\n",
      "       [ 0.1885265 ,  0.18701055,  0.25730787,  0.08828717]])\n",
      "array([[ 0.36128458,  0.50919586,  0.69936589,  1.        ],\n",
      "       [ 0.26262183,         nan,  0.38332471, -1.        ],\n",
      "       [ 0.1906914 ,  0.18730127,  0.25734833,  0.08832468]])\n",
      "----------------iteration 8, discount=0.7699999999999999----------------\n",
      "array([[ 0.36128458,  0.50919586,  0.69936589,  1.        ],\n",
      "       [ 0.26262183,         nan,  0.38332471, -1.        ],\n",
      "       [ 0.1906914 ,  0.18730127,  0.25734833,  0.08832468]])\n",
      "array([[ 0.36170544,  0.50922555,  0.69936718,  1.        ],\n",
      "       [ 0.26325431,         nan,  0.38332618, -1.        ],\n",
      "       [ 0.19127009,  0.18737097,  0.25735749,  0.08833322]])\n",
      "----------------iteration 9, discount=0.7699999999999999----------------\n",
      "array([[ 0.36170544,  0.50922555,  0.69936718,  1.        ],\n",
      "       [ 0.26325431,         nan,  0.38332618, -1.        ],\n",
      "       [ 0.19127009,  0.18737097,  0.25735749,  0.08833322]])\n",
      "array([[ 0.36180484,  0.50923092,  0.69936739,  1.        ],\n",
      "       [ 0.26341295,         nan,  0.38332643, -1.        ],\n",
      "       [ 0.19141774,  0.18738735,  0.25735956,  0.08833515]])\n",
      "---------------iteration 10, discount=0.7699999999999999----------------\n",
      "array([[ 0.36180484,  0.50923092,  0.69936739,  1.        ],\n",
      "       [ 0.26341295,         nan,  0.38332643, -1.        ],\n",
      "       [ 0.19141774,  0.18738735,  0.25735956,  0.08833515]])\n",
      "array([[ 0.36182801,  0.50923187,  0.69936742,  1.        ],\n",
      "       [ 0.26345165,         nan,  0.38332647, -1.        ],\n",
      "       [ 0.19145421,  0.18739114,  0.25736003,  0.08833558]])\n",
      "array([[  0.,   1.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7599999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7599999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.608     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.293664  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.17854771,  0.03255701]])\n",
      "----------------iteration 2, discount=0.7599999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.608     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.293664  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.17854771,  0.03255701]])\n",
      "array([[ 0.        ,  0.369664  ,  0.67652646,  1.        ],\n",
      "       [ 0.        ,         nan,  0.35764655, -1.        ],\n",
      "       [ 0.        ,  0.10855701,  0.22817377,  0.06520398]])\n",
      "----------------iteration 3, discount=0.7599999999999999----------------\n",
      "array([[ 0.        ,  0.369664  ,  0.67652646,  1.        ],\n",
      "       [ 0.        ,         nan,  0.35764655, -1.        ],\n",
      "       [ 0.        ,  0.10855701,  0.22817377,  0.06520398]])\n",
      "array([[ 0.22475571,  0.46751702,  0.68659715,  1.        ],\n",
      "       [ 0.13665147,         nan,  0.3686322 , -1.        ],\n",
      "       [ 0.09133443,  0.15523032,  0.24088139,  0.07541139]])\n",
      "----------------iteration 4, discount=0.7599999999999999----------------\n",
      "array([[ 0.22475571,  0.46751702,  0.68659715,  1.        ],\n",
      "       [ 0.13665147,         nan,  0.3686322 , -1.        ],\n",
      "       [ 0.09133443,  0.15523032,  0.24088139,  0.07541139]])\n",
      "array([[ 0.31171729,  0.48851365,  0.68819743,  1.        ],\n",
      "       [ 0.21029514,         nan,  0.37044009, -1.        ],\n",
      "       [ 0.14659836,  0.17005089,  0.24388271,  0.07801195]])\n",
      "----------------iteration 5, discount=0.7599999999999999----------------\n",
      "array([[ 0.31171729,  0.48851365,  0.68819743,  1.        ],\n",
      "       [ 0.21029514,         nan,  0.37044009, -1.        ],\n",
      "       [ 0.14659836,  0.17005089,  0.24388271,  0.07801195]])\n",
      "array([[ 0.33668925,  0.49267811,  0.68845645,  1.        ],\n",
      "       [ 0.23667192,         nan,  0.37073497, -1.        ],\n",
      "       [ 0.16796187,  0.17412842,  0.24456953,  0.07862718]])\n",
      "----------------iteration 6, discount=0.7599999999999999----------------\n",
      "array([[ 0.33668925,  0.49267811,  0.68845645,  1.        ],\n",
      "       [ 0.23667192,         nan,  0.37073497, -1.        ],\n",
      "       [ 0.16796187,  0.17412842,  0.24456953,  0.07862718]])\n",
      "array([[ 0.34312374,  0.4934686 ,  0.68849855,  1.        ],\n",
      "       [ 0.24459337,         nan,  0.37078297, -1.        ],\n",
      "       [ 0.17471163,  0.17516579,  0.24472431,  0.07876805]])\n",
      "----------------iteration 7, discount=0.7599999999999999----------------\n",
      "array([[ 0.34312374,  0.4934686 ,  0.68849855,  1.        ],\n",
      "       [ 0.24459337,         nan,  0.37078297, -1.        ],\n",
      "       [ 0.17471163,  0.17516579,  0.24472431,  0.07876805]])\n",
      "array([[ 0.34469541,  0.49361434,  0.6885054 ,  1.        ],\n",
      "       [ 0.246753  ,         nan,  0.37079079, -1.        ],\n",
      "       [ 0.17661651,  0.17541758,  0.24475891,  0.07879979]])\n",
      "----------------iteration 8, discount=0.7599999999999999----------------\n",
      "array([[ 0.34469541,  0.49361434,  0.6885054 ,  1.        ],\n",
      "       [ 0.246753  ,         nan,  0.37079079, -1.        ],\n",
      "       [ 0.17661651,  0.17541758,  0.24475891,  0.07879979]])\n",
      "array([[ 0.3450676 ,  0.49364066,  0.68850651,  1.        ],\n",
      "       [ 0.24730756,         nan,  0.37079206, -1.        ],\n",
      "       [ 0.17711759,  0.17547689,  0.2447666 ,  0.07880688]])\n",
      "----------------iteration 9, discount=0.7599999999999999----------------\n",
      "array([[ 0.3450676 ,  0.49364066,  0.68850651,  1.        ],\n",
      "       [ 0.24730756,         nan,  0.37079206, -1.        ],\n",
      "       [ 0.17711759,  0.17547689,  0.2447666 ,  0.07880688]])\n",
      "array([[ 0.34515403,  0.49364534,  0.68850669,  1.        ],\n",
      "       [ 0.2474444 ,         nan,  0.37079226, -1.        ],\n",
      "       [ 0.17724338,  0.17549058,  0.2447683 ,  0.07880845]])\n",
      "---------------iteration 10, discount=0.7599999999999999----------------\n",
      "array([[ 0.34515403,  0.49364534,  0.68850669,  1.        ],\n",
      "       [ 0.2474444 ,         nan,  0.37079226, -1.        ],\n",
      "       [ 0.17724338,  0.17549058,  0.2447683 ,  0.07880845]])\n",
      "array([[ 0.34517385,  0.49364616,  0.68850672,  1.        ],\n",
      "       [ 0.24747725,         nan,  0.3707923 , -1.        ],\n",
      "       [ 0.17727395,  0.1754937 ,  0.24476868,  0.0788088 ]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7499999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7499999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.    ,  0.    ,  0.6   ,  1.    ],\n",
      "       [ 0.    ,     nan,  0.285 , -1.    ],\n",
      "       [ 0.    ,  0.    ,  0.171 ,  0.0276]])\n",
      "----------------iteration 2, discount=0.7499999999999999----------------\n",
      "array([[ 0.    ,  0.    ,  0.6   ,  1.    ],\n",
      "       [ 0.    ,     nan,  0.285 , -1.    ],\n",
      "       [ 0.    ,  0.    ,  0.171 ,  0.0276]])\n",
      "array([[ 0.      ,  0.36    ,  0.666375,  1.      ],\n",
      "       [ 0.      ,       nan,  0.3462  , -1.      ],\n",
      "       [ 0.      ,  0.1026  ,  0.217485,  0.057561]])\n",
      "----------------iteration 3, discount=0.7499999999999999----------------\n",
      "array([[ 0.      ,  0.36    ,  0.666375,  1.      ],\n",
      "       [ 0.      ,       nan,  0.3462  , -1.      ],\n",
      "       [ 0.      ,  0.1026  ,  0.217485,  0.057561]])\n",
      "array([[ 0.216     ,  0.453825  ,  0.67594312,  1.        ],\n",
      "       [ 0.1296    ,         nan,  0.35653087, -1.        ],\n",
      "       [ 0.085455  ,  0.145881  ,  0.22917667,  0.06682308]])\n",
      "----------------iteration 4, discount=0.7499999999999999----------------\n",
      "array([[ 0.216     ,  0.453825  ,  0.67594312,  1.        ],\n",
      "       [ 0.1296    ,         nan,  0.35653087, -1.        ],\n",
      "       [ 0.085455  ,  0.145881  ,  0.22917667,  0.06682308]])\n",
      "array([[ 0.298215  ,  0.47363962,  0.67743555,  1.        ],\n",
      "       [ 0.198369  ,         nan,  0.35820115, -1.        ],\n",
      "       [ 0.1363716 ,  0.15938815,  0.23188653,  0.06914365]])\n",
      "----------------iteration 5, discount=0.7499999999999999----------------\n",
      "array([[ 0.298215  ,  0.47363962,  0.67743555,  1.        ],\n",
      "       [ 0.198369  ,         nan,  0.35820115, -1.        ],\n",
      "       [ 0.1363716 ,  0.15938815,  0.23188653,  0.06914365]])\n",
      "array([[ 0.32142757,  0.47750727,  0.67767275,  1.        ],\n",
      "       [ 0.22261189,         nan,  0.35846874, -1.        ],\n",
      "       [ 0.15574912,  0.16304014,  0.23249503,  0.06968279]])\n",
      "----------------iteration 6, discount=0.7499999999999999----------------\n",
      "array([[ 0.32142757,  0.47750727,  0.67767275,  1.        ],\n",
      "       [ 0.22261189,         nan,  0.35846874, -1.        ],\n",
      "       [ 0.15574912,  0.16304014,  0.23249503,  0.06968279]])\n",
      "array([[ 0.32730732,  0.47822974,  0.67771061,  1.        ],\n",
      "       [ 0.22977618,         nan,  0.35851152, -1.        ],\n",
      "       [ 0.1617749 ,  0.16395304,  0.2326296 ,  0.06980397]])\n",
      "----------------iteration 7, discount=0.7499999999999999----------------\n",
      "array([[ 0.32730732,  0.47822974,  0.67771061,  1.        ],\n",
      "       [ 0.22977618,         nan,  0.35851152, -1.        ],\n",
      "       [ 0.1617749 ,  0.16395304,  0.2326296 ,  0.06980397]])\n",
      "array([[ 0.32871911,  0.47836083,  0.67771666,  1.        ],\n",
      "       [ 0.23169789,         nan,  0.35851836, -1.        ],\n",
      "       [ 0.16344833,  0.16417072,  0.23265912,  0.06983077]])\n",
      "----------------iteration 8, discount=0.7499999999999999----------------\n",
      "array([[ 0.32871911,  0.47836083,  0.67771666,  1.        ],\n",
      "       [ 0.23169789,         nan,  0.35851836, -1.        ],\n",
      "       [ 0.16344833,  0.16417072,  0.23265912,  0.06983077]])\n",
      "array([[ 0.32904777,  0.47838412,  0.67771763,  1.        ],\n",
      "       [ 0.23218335,         nan,  0.35851945, -1.        ],\n",
      "       [ 0.16388144,  0.16422108,  0.23266556,  0.06983664]])\n",
      "----------------iteration 9, discount=0.7499999999999999----------------\n",
      "array([[ 0.32904777,  0.47838412,  0.67771763,  1.        ],\n",
      "       [ 0.23218335,         nan,  0.35851945, -1.        ],\n",
      "       [ 0.16388144,  0.16422108,  0.23266556,  0.06983664]])\n",
      "array([[ 0.32912281,  0.47838819,  0.67771778,  1.        ],\n",
      "       [ 0.23230119,         nan,  0.35851963, -1.        ],\n",
      "       [ 0.1639884 ,  0.1642325 ,  0.23266696,  0.06983793]])\n",
      "---------------iteration 10, discount=0.7499999999999999----------------\n",
      "array([[ 0.32912281,  0.47838819,  0.67771778,  1.        ],\n",
      "       [ 0.23230119,         nan,  0.35851963, -1.        ],\n",
      "       [ 0.1639884 ,  0.1642325 ,  0.23266696,  0.06983793]])\n",
      "array([[ 0.32913972,  0.4783889 ,  0.67771781,  1.        ],\n",
      "       [ 0.23232901,         nan,  0.35851966, -1.        ],\n",
      "       [ 0.16401397,  0.16423505,  0.23266727,  0.0698382 ]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7399999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7399999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.592     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.276464  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.16366669,  0.02289068]])\n",
      "----------------iteration 2, discount=0.7399999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.592     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.276464  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.16366669,  0.02289068]])\n",
      "array([[ 0.        ,  0.350464  ,  0.65626634,  1.        ],\n",
      "       [ 0.        ,         nan,  0.33496801, -1.        ],\n",
      "       [ 0.        ,  0.09689068,  0.20716488,  0.05033552]])\n",
      "----------------iteration 3, discount=0.7399999999999999----------------\n",
      "array([[ 0.        ,  0.350464  ,  0.65626634,  1.        ],\n",
      "       [ 0.        ,         nan,  0.33496801, -1.        ],\n",
      "       [ 0.        ,  0.09689068,  0.20716488,  0.05033552]])\n",
      "array([[ 0.20747469,  0.44037834,  0.66535134,  1.        ],\n",
      "       [ 0.12282502,         nan,  0.34467563, -1.        ],\n",
      "       [ 0.07988232,  0.13698143,  0.21790943,  0.05872721]])\n",
      "----------------iteration 4, discount=0.7399999999999999----------------\n",
      "array([[ 0.20747469,  0.44037834,  0.66535134,  1.        ],\n",
      "       [ 0.12282502,         nan,  0.34467563, -1.        ],\n",
      "       [ 0.07988232,  0.13698143,  0.21790943,  0.05872721]])\n",
      "array([[ 0.28514616,  0.45906399,  0.666742  ,  1.        ],\n",
      "       [ 0.18698463,         nan,  0.34621726, -1.        ],\n",
      "       [ 0.12674282,  0.14927563,  0.22035283,  0.06079469]])\n",
      "----------------iteration 5, discount=0.7399999999999999----------------\n",
      "array([[ 0.28514616,  0.45906399,  0.666742  ,  1.        ],\n",
      "       [ 0.18698463,         nan,  0.34621726, -1.        ],\n",
      "       [ 0.12674282,  0.14927563,  0.22035283,  0.06079469]])\n",
      "array([[ 0.30670356,  0.46265273,  0.66695898,  1.        ],\n",
      "       [ 0.20924223,         nan,  0.3464598 , -1.        ],\n",
      "       [ 0.14429677,  0.15254167,  0.22089109,  0.06126633]])\n",
      "----------------iteration 6, discount=0.7399999999999999----------------\n",
      "array([[ 0.30670356,  0.46265273,  0.66695898,  1.        ],\n",
      "       [ 0.20924223,         nan,  0.3464598 , -1.        ],\n",
      "       [ 0.14429677,  0.15254167,  0.22089109,  0.06126633]])\n",
      "array([[ 0.31207041,  0.46331232,  0.66699299,  1.        ],\n",
      "       [ 0.21571353,         nan,  0.34649787, -1.        ],\n",
      "       [ 0.14966845,  0.15334369,  0.22100788,  0.06137038]])\n",
      "----------------iteration 7, discount=0.7399999999999999----------------\n",
      "array([[ 0.31207041,  0.46331232,  0.66699299,  1.        ],\n",
      "       [ 0.21571353,         nan,  0.34649787, -1.        ],\n",
      "       [ 0.14966845,  0.15334369,  0.22100788,  0.06137038]])\n",
      "array([[ 0.31333691,  0.46343007,  0.66699832,  1.        ],\n",
      "       [ 0.21742105,         nan,  0.34650385, -1.        ],\n",
      "       [ 0.15113616,  0.15353153,  0.22103302,  0.06139296]])\n",
      "----------------iteration 8, discount=0.7399999999999999----------------\n",
      "array([[ 0.31333691,  0.46343007,  0.66699832,  1.        ],\n",
      "       [ 0.21742105,         nan,  0.34650385, -1.        ],\n",
      "       [ 0.15113616,  0.15353153,  0.22103302,  0.06139296]])\n",
      "array([[ 0.31362669,  0.46345066,  0.66699916,  1.        ],\n",
      "       [ 0.21784532,         nan,  0.34650479, -1.        ],\n",
      "       [ 0.15150984,  0.15357422,  0.22103841,  0.06139781]])\n",
      "----------------iteration 9, discount=0.7399999999999999----------------\n",
      "array([[ 0.31362669,  0.46345066,  0.66699916,  1.        ],\n",
      "       [ 0.21784532,         nan,  0.34650479, -1.        ],\n",
      "       [ 0.15150984,  0.15357422,  0.22103841,  0.06139781]])\n",
      "array([[ 0.31369172,  0.4634542 ,  0.66699929,  1.        ],\n",
      "       [ 0.2179466 ,         nan,  0.34650494, -1.        ],\n",
      "       [ 0.15160061,  0.15358372,  0.22103956,  0.06139886]])\n",
      "---------------iteration 10, discount=0.7399999999999999----------------\n",
      "array([[ 0.31369172,  0.4634542 ,  0.66699929,  1.        ],\n",
      "       [ 0.2179466 ,         nan,  0.34650494, -1.        ],\n",
      "       [ 0.15160061,  0.15358372,  0.22103956,  0.06139886]])\n",
      "array([[ 0.31370612,  0.4634548 ,  0.66699931,  1.        ],\n",
      "       [ 0.21797012,         nan,  0.34650496, -1.        ],\n",
      "       [ 0.15162195,  0.15358581,  0.2210398 ,  0.06139908]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7299999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7299999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.584     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.268056  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.1565447 ,  0.01842211]])\n",
      "----------------iteration 2, discount=0.7299999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.584     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.268056  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.1565447 ,  0.01842211]])\n",
      "array([[ 0.        ,  0.341056  ,  0.64620009,  1.        ],\n",
      "       [ 0.        ,         nan,  0.32394894, -1.        ],\n",
      "       [ 0.        ,  0.09142211,  0.19720481,  0.04351242]])\n",
      "----------------iteration 3, discount=0.7299999999999999----------------\n",
      "array([[ 0.        ,  0.341056  ,  0.64620009,  1.        ],\n",
      "       [ 0.        ,         nan,  0.32394894, -1.        ],\n",
      "       [ 0.        ,  0.09142211,  0.19720481,  0.04351242]])\n",
      "array([[ 0.1991767 ,  0.42717503,  0.65482088,  1.        ],\n",
      "       [ 0.1163192 ,         nan,  0.33306367, -1.        ],\n",
      "       [ 0.07460422,  0.12851524,  0.2070672 ,  0.05110365]])\n",
      "----------------iteration 4, discount=0.7299999999999999----------------\n",
      "array([[ 0.1991767 ,  0.42717503,  0.65482088,  1.        ],\n",
      "       [ 0.1163192 ,         nan,  0.33306367, -1.        ],\n",
      "       [ 0.07460422,  0.12851524,  0.2070672 ,  0.05110365]])\n",
      "array([[ 0.27250142,  0.44478295,  0.65611557,  1.        ],\n",
      "       [ 0.17612343,         nan,  0.33448514, -1.        ],\n",
      "       [ 0.1176838 ,  0.13969047,  0.20926729,  0.05294267]])\n",
      "----------------iteration 5, discount=0.7299999999999999----------------\n",
      "array([[ 0.27250142,  0.44478295,  0.65611557,  1.        ],\n",
      "       [ 0.17612343,         nan,  0.33448514, -1.        ],\n",
      "       [ 0.1176838 ,  0.13969047,  0.20926729,  0.05294267]])\n",
      "array([[ 0.29250286,  0.4481098 ,  0.65631385,  1.        ],\n",
      "       [ 0.19653569,         nan,  0.3347047 , -1.        ],\n",
      "       [ 0.13356516,  0.14260691,  0.20974267,  0.05335453]])\n",
      "----------------iteration 6, discount=0.7299999999999999----------------\n",
      "array([[ 0.29250286,  0.4481098 ,  0.65631385,  1.        ],\n",
      "       [ 0.19653569,         nan,  0.3347047 , -1.        ],\n",
      "       [ 0.13356516,  0.14260691,  0.20974267,  0.05335453]])\n",
      "array([[ 0.29739594,  0.44871132,  0.65634435,  1.        ],\n",
      "       [ 0.20237344,         nan,  0.33473855, -1.        ],\n",
      "       [ 0.13834665,  0.14331033,  0.20984385,  0.05344369]])\n",
      "----------------iteration 7, discount=0.7299999999999999----------------\n",
      "array([[ 0.29739594,  0.44871132,  0.65634435,  1.        ],\n",
      "       [ 0.20237344,         nan,  0.33473855, -1.        ],\n",
      "       [ 0.13834665,  0.14331033,  0.20984385,  0.05344369]])\n",
      "array([[ 0.29853058,  0.44881696,  0.65634905,  1.        ],\n",
      "       [ 0.20388838,         nan,  0.33474376, -1.        ],\n",
      "       [ 0.13963177,  0.14347211,  0.20986521,  0.05346267]])\n",
      "----------------iteration 8, discount=0.7299999999999999----------------\n",
      "array([[ 0.29853058,  0.44881696,  0.65634905,  1.        ],\n",
      "       [ 0.20388838,         nan,  0.33474376, -1.        ],\n",
      "       [ 0.13963177,  0.14347211,  0.20986521,  0.05346267]])\n",
      "array([[ 0.29878569,  0.44883512,  0.65634978,  1.        ],\n",
      "       [ 0.20425854,         nan,  0.33474456, -1.        ],\n",
      "       [ 0.13995357,  0.14350821,  0.2098697 ,  0.05346668]])\n",
      "----------------iteration 9, discount=0.7299999999999999----------------\n",
      "array([[ 0.29878569,  0.44883512,  0.65634978,  1.        ],\n",
      "       [ 0.20425854,         nan,  0.33474456, -1.        ],\n",
      "       [ 0.13995357,  0.14350821,  0.2098697 ,  0.05346668]])\n",
      "array([[ 0.29884194,  0.4488382 ,  0.65634989,  1.        ],\n",
      "       [ 0.20434544,         nan,  0.33474469, -1.        ],\n",
      "       [ 0.14003045,  0.1435161 ,  0.20987064,  0.05346752]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7199999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7199999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.576     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.259776  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.14963098,  0.01418744]])\n",
      "----------------iteration 2, discount=0.7199999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.576     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.259776  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.14963098,  0.01418744]])\n",
      "array([[ 0.        ,  0.331776  ,  0.63617587,  1.        ],\n",
      "       [ 0.        ,         nan,  0.31314117, -1.        ],\n",
      "       [ 0.        ,  0.08618744,  0.18759631,  0.03707697]])\n",
      "----------------iteration 3, discount=0.7199999999999999----------------\n",
      "array([[ 0.        ,  0.331776  ,  0.63617587,  1.        ],\n",
      "       [ 0.        ,         nan,  0.31314117, -1.        ],\n",
      "       [ 0.        ,  0.08618744,  0.18759631,  0.03707697]])\n",
      "array([[ 0.19110298,  0.41421305,  0.64435083,  1.        ],\n",
      "       [ 0.11007531,         nan,  0.32169224, -1.        ],\n",
      "       [ 0.06960888,  0.12046647,  0.19663786,  0.04393295]])\n",
      "----------------iteration 4, discount=0.7199999999999999----------------\n",
      "array([[ 0.19110298,  0.41421305,  0.64435083,  1.        ],\n",
      "       [ 0.11007531,         nan,  0.32169224, -1.        ],\n",
      "       [ 0.06960888,  0.12046647,  0.19663786,  0.04393295]])\n",
      "array([[ 0.26027155,  0.43079276,  0.6455551 ,  1.        ],\n",
      "       [ 0.16576726,         nan,  0.32300158, -1.        ],\n",
      "       [ 0.10916737,  0.13061058,  0.19861604,  0.04556601]])\n",
      "----------------iteration 5, discount=0.7199999999999999----------------\n",
      "array([[ 0.26027155,  0.43079276,  0.6455551 ,  1.        ],\n",
      "       [ 0.16576726,         nan,  0.32300158, -1.        ],\n",
      "       [ 0.10916737,  0.13061058,  0.19861604,  0.04556601]])\n",
      "array([[ 0.27881142,  0.43387389,  0.64573608,  1.        ],\n",
      "       [ 0.18446586,         nan,  0.3232001 , -1.        ],\n",
      "       [ 0.12351635,  0.13321076,  0.19903518,  0.04592502]])\n",
      "----------------iteration 6, discount=0.7199999999999999----------------\n",
      "array([[ 0.27881142,  0.43387389,  0.64573608,  1.        ],\n",
      "       [ 0.18446586,         nan,  0.3232001 , -1.        ],\n",
      "       [ 0.12351635,  0.13321076,  0.19903518,  0.04592502]])\n",
      "array([[ 0.28326733,  0.43442182,  0.6457634 ,  1.        ],\n",
      "       [ 0.18972507,         nan,  0.32323013, -1.        ],\n",
      "       [ 0.12776599,  0.13382662,  0.19912267,  0.04600126]])\n",
      "----------------iteration 7, discount=0.7199999999999999----------------\n",
      "array([[ 0.28326733,  0.43442182,  0.6457634 ,  1.        ],\n",
      "       [ 0.18972507,         nan,  0.32323013, -1.        ],\n",
      "       [ 0.12776599,  0.13382662,  0.19912267,  0.04600126]])\n",
      "array([[ 0.28428242,  0.43451646,  0.64576753,  1.        ],\n",
      "       [ 0.19106708,         nan,  0.32323467, -1.        ],\n",
      "       [ 0.12888931,  0.13396569,  0.19914079,  0.04601719]])\n",
      "----------------iteration 8, discount=0.7199999999999999----------------\n",
      "array([[ 0.28428242,  0.43451646,  0.64576753,  1.        ],\n",
      "       [ 0.19106708,         nan,  0.32323467, -1.        ],\n",
      "       [ 0.12888931,  0.13396569,  0.19914079,  0.04601719]])\n",
      "array([[ 0.28450665,  0.43453247,  0.64576816,  1.        ],\n",
      "       [ 0.19138949,         nan,  0.32323536, -1.        ],\n",
      "       [ 0.12916591,  0.13399615,  0.19914453,  0.04602048]])\n",
      "----------------iteration 9, discount=0.7199999999999999----------------\n",
      "array([[ 0.28450665,  0.43453247,  0.64576816,  1.        ],\n",
      "       [ 0.19138949,         nan,  0.32323536, -1.        ],\n",
      "       [ 0.12916591,  0.13399615,  0.19914453,  0.04602048]])\n",
      "array([[ 0.28455522,  0.43453514,  0.64576825,  1.        ],\n",
      "       [ 0.1914639 ,         nan,  0.32323546, -1.        ],\n",
      "       [ 0.12923087,  0.13400269,  0.19914529,  0.04602116]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.7099999999999999----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.7099999999999999----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.568     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.251624  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.14292243,  0.01017994]])\n",
      "----------------iteration 2, discount=0.7099999999999999----------------\n",
      "array([[ 0.        ,  0.        ,  0.568     ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.251624  , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.14292243,  0.01017994]])\n",
      "array([[ 0.        ,  0.322624  ,  0.6261933 ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3025431 , -1.        ],\n",
      "       [ 0.        ,  0.08117994,  0.17833103,  0.0310148 ]])\n",
      "----------------iteration 3, discount=0.7099999999999999----------------\n",
      "array([[ 0.        ,  0.322624  ,  0.6261933 ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.3025431 , -1.        ],\n",
      "       [ 0.        ,  0.08117994,  0.17833103,  0.0310148 ]])\n",
      "array([[ 0.18325043,  0.4014904 ,  0.63394028,  1.        ],\n",
      "       [ 0.10408625,         nan,  0.31055864, -1.        ],\n",
      "       [ 0.06488476,  0.11281958,  0.18660955,  0.03719628]])\n",
      "----------------iteration 4, discount=0.7099999999999999----------------\n",
      "array([[ 0.18325043,  0.4014904 ,  0.63394028,  1.        ],\n",
      "       [ 0.10408625,         nan,  0.31055864, -1.        ],\n",
      "       [ 0.06488476,  0.11281958,  0.18660955,  0.03719628]])\n",
      "array([[ 0.24844745,  0.41708972,  0.63505942,  1.        ],\n",
      "       [ 0.1558984 ,         nan,  0.31176342, -1.        ],\n",
      "       [ 0.1011673 ,  0.1220146 ,  0.18838559,  0.03864395]])\n",
      "----------------iteration 5, discount=0.7099999999999999----------------\n",
      "array([[ 0.24844745,  0.41708972,  0.63505942,  1.        ],\n",
      "       [ 0.1558984 ,         nan,  0.31176342, -1.        ],\n",
      "       [ 0.1011673 ,  0.1220146 ,  0.18838559,  0.03864395]])\n",
      "array([[ 0.26561552,  0.41994049,  0.63522442,  1.        ],\n",
      "       [ 0.17300719,         nan,  0.31194267, -1.        ],\n",
      "       [ 0.114114  ,  0.12432909,  0.18875452,  0.03895629]])\n",
      "----------------iteration 6, discount=0.7099999999999999----------------\n",
      "array([[ 0.26561552,  0.41994049,  0.63522442,  1.        ],\n",
      "       [ 0.17300719,         nan,  0.31194267, -1.        ],\n",
      "       [ 0.114114  ,  0.12432909,  0.18875452,  0.03895629]])\n",
      "array([[ 0.26966841,  0.42043902,  0.63524886,  1.        ],\n",
      "       [ 0.17773868,         nan,  0.31196928, -1.        ],\n",
      "       [ 0.11788503,  0.1248673 ,  0.18883003,  0.03902135]])\n",
      "----------------iteration 7, discount=0.7099999999999999----------------\n",
      "array([[ 0.26966841,  0.42043902,  0.63524886,  1.        ],\n",
      "       [ 0.17773868,         nan,  0.31196928, -1.        ],\n",
      "       [ 0.11788503,  0.1248673 ,  0.18883003,  0.03902135]])\n",
      "array([[ 0.27057527,  0.4205237 ,  0.63525249,  1.        ],\n",
      "       [ 0.17892564,         nan,  0.31197323, -1.        ],\n",
      "       [ 0.11886518,  0.12498661,  0.18884536,  0.03903468]])\n",
      "----------------iteration 8, discount=0.7099999999999999----------------\n",
      "array([[ 0.27057527,  0.4205237 ,  0.63525249,  1.        ],\n",
      "       [ 0.17892564,         nan,  0.31197323, -1.        ],\n",
      "       [ 0.11886518,  0.12498661,  0.18884536,  0.03903468]])\n",
      "array([[ 0.27077202,  0.42053778,  0.63525303,  1.        ],\n",
      "       [ 0.17920595,         nan,  0.31197382, -1.        ],\n",
      "       [ 0.11910246,  0.12501226,  0.18884846,  0.03903739]])\n",
      "----------------iteration 9, discount=0.7099999999999999----------------\n",
      "array([[ 0.27077202,  0.42053778,  0.63525303,  1.        ],\n",
      "       [ 0.17920595,         nan,  0.31197382, -1.        ],\n",
      "       [ 0.11910246,  0.12501226,  0.18884846,  0.03903739]])\n",
      "array([[ 0.27081389,  0.42054008,  0.63525311,  1.        ],\n",
      "       [ 0.17926954,         nan,  0.31197391, -1.        ],\n",
      "       [ 0.11915724,  0.12501767,  0.18884909,  0.03903794]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'west']]\n",
      "----------------iteration 0, discount=0.6999999999999998----------------\n",
      "array([[ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.]])\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "----------------iteration 1, discount=0.6999999999999998----------------\n",
      "array([[  0.,   0.,   0.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "array([[ 0.        ,  0.        ,  0.56      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.2436    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.136416  ,  0.00954912]])\n",
      "----------------iteration 2, discount=0.6999999999999998----------------\n",
      "array([[ 0.        ,  0.        ,  0.56      ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.2436    , -1.        ],\n",
      "       [ 0.        ,  0.        ,  0.136416  ,  0.00954912]])\n",
      "array([[ 0.        ,  0.3136    ,  0.616252  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.29215312, -1.        ],\n",
      "       [ 0.        ,  0.07639296,  0.16962169,  0.02565659]])\n",
      "----------------iteration 3, discount=0.6999999999999998----------------\n",
      "array([[ 0.        ,  0.3136    ,  0.616252  ,  1.        ],\n",
      "       [ 0.        ,         nan,  0.29215312, -1.        ],\n",
      "       [ 0.        ,  0.07639296,  0.16962169,  0.02565659]])\n",
      "array([[ 0.175616  ,  0.38900512,  0.62358836,  1.        ],\n",
      "       [ 0.09834496,         nan,  0.2996602 , -1.        ],\n",
      "       [ 0.06042068,  0.10568316,  0.17700349,  0.03091792]])\n",
      "----------------iteration 4, discount=0.6999999999999998----------------\n",
      "array([[ 0.175616  ,  0.38900512,  0.62358836,  1.        ],\n",
      "       [ 0.09834496,         nan,  0.2996602 , -1.        ],\n",
      "       [ 0.06042068,  0.10568316,  0.17700349,  0.03091792]])\n",
      "array([[ 0.23702013,  0.4036702 ,  0.6246274 ,  1.        ],\n",
      "       [ 0.14649957,         nan,  0.30076756, -1.        ],\n",
      "       [ 0.09366703,  0.1139176 ,  0.17856832,  0.03216251]])\n",
      "----------------iteration 5, discount=0.6999999999999998----------------\n",
      "array([[ 0.23702013,  0.4036702 ,  0.6246274 ,  1.        ],\n",
      "       [ 0.14649957,         nan,  0.30076756, -1.        ],\n",
      "       [ 0.09366703,  0.1139176 ,  0.17856832,  0.03216251]])\n",
      "array([[ 0.25290169,  0.40630517,  0.62477765,  1.        ],\n",
      "       [ 0.16213489,         nan,  0.30092921, -1.        ],\n",
      "       [ 0.10532646,  0.11594672,  0.178888  ,  0.03278454]])\n",
      "----------------iteration 6, discount=0.6999999999999998----------------\n",
      "array([[ 0.25290169,  0.40630517,  0.62477765,  1.        ],\n",
      "       [ 0.16213489,         nan,  0.30092921, -1.        ],\n",
      "       [ 0.10532646,  0.11594672,  0.178888  ,  0.03278454]])\n",
      "array([[ 0.25658346,  0.40675821,  0.62479948,  1.        ],\n",
      "       [ 0.16638562,         nan,  0.30095275, -1.        ],\n",
      "       [ 0.10866507,  0.11640982,  0.17897715,  0.03318266]])\n",
      "----------------iteration 7, discount=0.6999999999999998----------------\n",
      "array([[ 0.25658346,  0.40675821,  0.62479948,  1.        ],\n",
      "       [ 0.16638562,         nan,  0.30095275, -1.        ],\n",
      "       [ 0.10866507,  0.11640982,  0.17897715,  0.03318266]])\n",
      "array([[ 0.25739243,  0.40683386,  0.62480266,  1.        ],\n",
      "       [ 0.16743375,         nan,  0.30095618, -1.        ],\n",
      "       [ 0.10951814,  0.11652458,  0.17901497,  0.03343613]])\n",
      "----------------iteration 8, discount=0.6999999999999998----------------\n",
      "array([[ 0.25739243,  0.40683386,  0.62480266,  1.        ],\n",
      "       [ 0.16743375,         nan,  0.30095618, -1.        ],\n",
      "       [ 0.10951814,  0.11652458,  0.17901497,  0.03343613]])\n",
      "array([[ 0.25756479,  0.40684623,  0.62480312,  1.        ],\n",
      "       [ 0.16767701,         nan,  0.30095668, -1.        ],\n",
      "       [ 0.10972212,  0.11656182,  0.1790356 ,  0.03359725]])\n",
      "----------------iteration 9, discount=0.6999999999999998----------------\n",
      "array([[ 0.25756479,  0.40684623,  0.62480312,  1.        ],\n",
      "       [ 0.16767701,         nan,  0.30095668, -1.        ],\n",
      "       [ 0.10972212,  0.11656182,  0.1790356 ,  0.03359725]])\n",
      "array([[ 0.25760081,  0.40684822,  0.62480319,  1.        ],\n",
      "       [ 0.16773124,         nan,  0.30095675, -1.        ],\n",
      "       [ 0.10976937,  0.11657859,  0.17904809,  0.03369963]])\n",
      "---------------iteration 10, discount=0.6999999999999998----------------\n",
      "array([[ 0.25760081,  0.40684822,  0.62480319,  1.        ],\n",
      "       [ 0.16773124,         nan,  0.30095675, -1.        ],\n",
      "       [ 0.10976937,  0.11657859,  0.17904809,  0.03369963]])\n",
      "array([[ 0.25760825,  0.40684853,  0.6248032 ,  1.        ],\n",
      "       [ 0.16774299,         nan,  0.30095676, -1.        ],\n",
      "       [ 0.10978043,  0.11658793,  0.17905592,  0.03376468]])\n",
      "array([[  0.,   0.,   1.,   1.],\n",
      "       [  0.,  nan,   0.,  -1.],\n",
      "       [  0.,   0.,   0.,   0.]])\n",
      "[['east', 'east', 'east', ''],\n",
      " ['north', '', 'north', ''],\n",
      " ['north', 'east', 'north', 'south']]\n",
      "Policy iteration: None\n"
     ]
    }
   ],
   "source": [
    "print ('Policy iteration:',part_c())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env= GridWorld(world_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   1.],\n",
       "       [  0.,  nan,   0.,  -1.],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# world height\n",
    "WORLD_HEIGHT = 3\n",
    "\n",
    "# world width\n",
    "WORLD_WIDTH = 4\n",
    "\n",
    "# probability for exploration\n",
    "EPSILON = 0.1\n",
    "\n",
    "# step size\n",
    "ALPHA = 0.5\n",
    "\n",
    "# gamma for Q-Learning and Expected Sarsa\n",
    "GAMMA = 1\n",
    "\n",
    "# all possible actions\n",
    "ACTION_UP = 0\n",
    "ACTION_DOWN = 1\n",
    "ACTION_LEFT = 2\n",
    "ACTION_RIGHT = 3\n",
    "ACTIONS = [ACTION_UP, ACTION_DOWN, ACTION_LEFT, ACTION_RIGHT]\n",
    "\n",
    "# initial state action pair values\n",
    "START = [2, 0]\n",
    "GOAL = [0,3]\n",
    "BLOCK= [1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action):\n",
    "    i, j = state\n",
    "    if action == ACTION_UP:\n",
    "        next_state = [max(i - 1, 0), j]\n",
    "    elif action == ACTION_LEFT:\n",
    "        next_state = [i, max(j - 1, 0)]\n",
    "    elif action == ACTION_RIGHT:\n",
    "        next_state = [i, min(j + 1, WORLD_WIDTH - 1)]\n",
    "    elif action == ACTION_DOWN:\n",
    "        next_state = [min(i + 1, WORLD_HEIGHT - 1), j]\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    reward = -1\n",
    "    if (i == 1 and j == 3):\n",
    "        reward = -100\n",
    "        next_state = START\n",
    "\n",
    "    return next_state, reward\n",
    "\n",
    "\n",
    "    if (action== ACTION_DOWN and state== BLOCK):\n",
    "        reward= 0.0\n",
    "        next_state= (action== ACTION_UP)\n",
    "    return next_state, reward\n",
    "\n",
    "    if (action== ACTION_UP and state== BLOCK):\n",
    "        reward= 0.0\n",
    "        next_state= (action== ACTION_DOWN)\n",
    "    return next_state, reward\n",
    "\n",
    "    if (action==ACTION_LEFT and state== BLOCK):\n",
    "        reward= 0.0\n",
    "        next_state= (action== ACTION_RIGHT)\n",
    "    return next_state, reward\n",
    "\n",
    "    \n",
    "\n",
    "    if (action== ACTION_RIGHT and state== BLOCK):\n",
    "        reward= 0.0\n",
    "        next_state= (action== ACTION_LEFT)\n",
    "    return next_state, reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if (action== ACTION_DOWN and state== BLOCK):\\n        next_state= [0,1]\\n    return next_state, reward\\n\\n    if (action== ACTION_UP and state== BLOCK):\\n        next_state= [2,1]\\n    return next_state, reward\\n\\n    if (action== ACTION_RIGHT and state== BLOCK):\\n        next_state= [1,0]\\n    \\n    return next_state, reward\\n\\n    if (action== ACTION_LEFT and state== BLOCK):\\n        next_state== [1,2]\\n    return next_state, reward'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"if (action== ACTION_DOWN and state== BLOCK):\n",
    "        next_state= [0,1]\n",
    "    return next_state, reward\n",
    "\n",
    "    if (action== ACTION_UP and state== BLOCK):\n",
    "        next_state= [2,1]\n",
    "    return next_state, reward\n",
    "\n",
    "    if (action== ACTION_RIGHT and state== BLOCK):\n",
    "        next_state= [1,0]\n",
    "    \n",
    "    return next_state, reward\n",
    "\n",
    "    if (action== ACTION_LEFT and state== BLOCK):\n",
    "        next_state== [1,2]\n",
    "    return next_state, reward\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_value= np.zeros((9,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_action(state, q_value):\n",
    "    if np.random.binomial(1, EPSILON) == 1:\n",
    "        return np.random.choice(ACTIONS)\n",
    "    else:\n",
    "        values_ = q_value[state[0], state[1], :]\n",
    "        return np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sarsa(q_value, expected=False, step_size=ALPHA):\n",
    "    state = START\n",
    "    action = choose_action(state, q_value)\n",
    "    rewards = 0.0\n",
    "    while state != GOAL:\n",
    "        next_state, reward = step(state, action)\n",
    "        next_action = choose_action(next_state, q_value)\n",
    "        rewards += reward\n",
    "        if not expected:\n",
    "            target = q_value[next_state[0], next_state[1], next_action]\n",
    "        else:\n",
    "            # calculate the expected value of new state\n",
    "            target = 0.0\n",
    "            q_next = q_value[next_state[0], next_state[1], :]\n",
    "            best_actions = np.argwhere(q_next == np.max(q_next))\n",
    "            for action_ in ACTIONS:\n",
    "                if action_ in best_actions:\n",
    "                    target += ((1.0 - EPSILON) / len(best_actions) + EPSILON / len(ACTIONS)) * q_value[next_state[0], next_state[1], action_]\n",
    "                else:\n",
    "                    target += EPSILON / len(ACTIONS) * q_value[next_state[0], next_state[1], action_]\n",
    "        target *= GAMMA\n",
    "        q_value[state[0], state[1], action] += step_size * (\n",
    "                reward + target - q_value[state[0], state[1], action])\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_learning(q_value, step_size=ALPHA):\n",
    "    state = START\n",
    "    rewards = 0.0\n",
    "    while state != GOAL:\n",
    "        action = choose_action(state, q_value)\n",
    "        next_state, reward = step(state, action)\n",
    "        rewards += reward\n",
    "        # Q-Learning update\n",
    "        q_value[state[0], state[1], action] += step_size * (\n",
    "                reward + GAMMA * np.max(q_value[next_state[0], next_state[1], :]) -\n",
    "                q_value[state[0], state[1], action])\n",
    "        state = next_state\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_optimal_policy(q_value):\n",
    "    optimal_policy = []\n",
    "    for i in range(0, WORLD_HEIGHT):\n",
    "        optimal_policy.append([])\n",
    "        for j in range(0, WORLD_WIDTH):\n",
    "            if [i, j] == GOAL:\n",
    "                optimal_policy[-1].append('G')\n",
    "                continue\n",
    "            bestAction = np.argmax(q_value[i, j, :])\n",
    "            if bestAction == ACTION_UP:\n",
    "                optimal_policy[-1].append('U')\n",
    "            elif bestAction == ACTION_DOWN:\n",
    "                optimal_policy[-1].append('D')\n",
    "            elif bestAction == ACTION_LEFT:\n",
    "                optimal_policy[-1].append('L')\n",
    "            elif bestAction == ACTION_RIGHT:\n",
    "                optimal_policy[-1].append('R')\n",
    "    for row in optimal_policy:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figure_6_4():\n",
    "    # episodes of each run\n",
    "    episodes = 1000\n",
    "\n",
    "    # perform 40 independent runs\n",
    "    runs = 1\n",
    "\n",
    "    rewards_sarsa = np.zeros(episodes)\n",
    "    rewards_q_learning = np.zeros(episodes)\n",
    "    for r in tqdm(range(runs)):\n",
    "        q_sarsa = np.zeros((WORLD_HEIGHT, WORLD_WIDTH, 4))\n",
    "        q_q_learning = np.copy(q_sarsa)\n",
    "        for i in range(0, episodes):\n",
    "            # cut off the value by -100 to draw the figure more elegantly\n",
    "            rewards_sarsa[i] += max(sarsa(q_sarsa), -100)\n",
    "            rewards_q_learning[i] += max(q_learning(q_q_learning), -100)\n",
    "            #rewards_sarsa[i] += sarsa(q_sarsa)\n",
    "            #rewards_q_learning[i] += q_learning(q_q_learning)\n",
    "\n",
    "    # averaging over independt runs\n",
    "    rewards_sarsa /= runs\n",
    "    rewards_q_learning /= runs\n",
    "\n",
    "    # draw reward curves\n",
    "    plt.plot(rewards_sarsa, label='Sarsa')\n",
    "    plt.plot(rewards_q_learning, label='Q-Learning')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Sum of rewards during episode')\n",
    "    #plt.ylim([-100, 0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #plt.savefig('Game theory/figure_6_4.png')\n",
    "    plt.close()\n",
    "\n",
    "    # display optimal policy\n",
    "    print('Sarsa Optimal Policy:')\n",
    "    print_optimal_policy(q_sarsa)\n",
    "    print('Q-Learning Optimal Policy:')\n",
    "    print_optimal_policy(q_q_learning)\n",
    "    print(\"Rewards for Sarsa\", rewards_sarsa)\n",
    "    print(\"Rewards for Q_learning\", rewards_q_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFACAYAAAA8gUGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzszMzCwzTuDMzMzMMuMEzszMzCwz/x9X8uTMoZPuQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarsa Optimal Policy:\n",
      "['R', 'U', 'R', 'G']\n",
      "['U', 'U', 'U', 'U']\n",
      "['U', 'L', 'L', 'D']\n",
      "Q-Learning Optimal Policy:\n",
      "['R', 'R', 'R', 'G']\n",
      "['U', 'U', 'U', 'D']\n",
      "['U', 'U', 'U', 'L']\n",
      "Rewards for Sarsa [-100. -100. -100. -100.  -17.   -7.   -5.   -5.   -9.  -17.   -7.   -9.\n",
      "  -12.  -12.   -7.  -17.  -11.   -7.   -7.   -9.  -11.   -5.   -7.   -5.\n",
      "   -5.  -11.   -5.   -7.   -5.   -6. -100.   -7.   -6.   -6. -100.   -5.\n",
      "   -5.   -6.   -5.   -5.   -5.   -7.   -7.   -6.   -5.   -5.   -5.   -5.\n",
      " -100.   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -7.  -26.   -6.   -7.   -5.   -5.   -5.   -7.   -7.   -6.  -13.\n",
      "   -5.   -6.   -5.   -7.   -7.   -5. -100.  -50.   -7.   -7.   -5.  -11.\n",
      "   -5.   -6.   -9.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -5.   -5.   -7.  -10.   -5.   -7.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -7.   -5.   -6.   -8.   -7.   -5.   -5.   -6.   -5.   -6.   -5.\n",
      "   -5.   -7.  -13.  -14.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -5.   -6.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -7.   -6.\n",
      "   -6.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -6.   -7.   -5.   -7.\n",
      "   -5.   -6.   -5.   -5.   -7.   -5.   -6.   -5.   -5.  -18.   -7.   -5.\n",
      "   -9.   -5.   -7.   -5.   -5.   -6.   -5.   -5.  -12.   -5.   -6.   -5.\n",
      "  -11.   -5.   -5.   -5.   -8.   -5.   -5.   -5.   -6.   -5.   -5.   -5.\n",
      "   -6.   -7.   -6.   -5.   -5.   -5.   -5.  -11.   -6.   -5.   -5.   -7.\n",
      "   -5.   -6.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -8.   -5.  -11.\n",
      "   -5.   -7.   -8.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -8.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -6.   -6.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -9.  -15.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.\n",
      "   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -7.   -5.   -7.   -5.\n",
      "   -5.   -7.   -7.   -6.   -5.   -7.   -6.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -6.   -7.\n",
      "   -5.   -5.  -11.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -9.\n",
      "  -14.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -6.   -5.\n",
      "   -5.   -5.   -5.   -5.  -14.   -5.   -5.   -5.   -6.   -7.   -9.   -7.\n",
      "   -7.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "  -11.   -6.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -7.   -5.\n",
      "   -6.   -5.   -5.   -5.   -7.   -7.   -7.   -6.   -5.   -9.   -6.   -9.\n",
      "   -5.   -5.   -5.   -5.   -7.   -5.   -7.   -5.   -5.   -9.   -5.   -5.\n",
      "   -6.   -5.   -5.   -5.   -5.   -5.   -9.   -5.   -7.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.\n",
      " -100.   -8.   -5.  -13.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -6.   -5.\n",
      "   -7.   -5.   -5.   -5.  -10.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -8.   -5.   -5.   -5.   -7.\n",
      "   -5.   -5.   -6.  -10.   -5.   -7.   -5.   -7.   -5.   -5.   -6.   -6.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -7.   -5.   -5.   -5.   -7.\n",
      "   -8.   -5.   -6.  -12.   -5.   -5.   -5.   -5.   -5.   -8.   -5.   -5.\n",
      "   -5.   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -6.   -6.   -5.  -12.\n",
      "   -6.   -5.   -5.   -6.  -10.   -5.   -5.  -16.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -6.   -5.   -6.   -6.   -5.   -7.   -9.   -5.   -5.   -5.   -7.\n",
      "   -5.   -7.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -6.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -6.   -7.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -6.   -5.   -5.   -5.   -5.   -7.\n",
      "   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.  -11.   -7.   -5.  -12.   -5.   -5.\n",
      "   -7.   -6.   -5.   -5.   -5.   -6.  -10.   -5.   -5.   -5.   -7.   -8.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -7.   -5.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -6.   -5.   -5.   -6.\n",
      "   -6.   -5.   -5.   -6.   -5.   -8.   -5.   -5.   -8.   -5.   -5.   -6.\n",
      "   -6.   -5.   -5.   -9.   -6.   -6.   -5.   -6.   -5.   -9.   -7.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -8.   -5.   -5.   -5.   -5.   -5.\n",
      "   -7.   -5.   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -6.   -6.   -7.   -5.\n",
      "  -10.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -9.   -5.   -5.   -5.\n",
      "   -5.   -6.   -6.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.  -10.\n",
      "   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -9.   -6.\n",
      "   -5.   -5.   -5.  -11.   -5.   -5.   -5.   -7.   -5.   -6.   -6.   -5.\n",
      "   -5.   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -8.   -5.   -6.\n",
      "   -7.   -5.  -11.   -5.   -6.   -7.   -5.   -6.   -5.   -7.   -7.   -5.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -7.   -5.   -5.\n",
      "   -5. -100.   -5.   -6.   -5.   -7.   -6.   -5.   -5.   -7.   -5.   -5.\n",
      "   -9.   -5.   -5.   -7.   -6.   -5.   -7.   -5.   -5.   -6.   -5.   -5.\n",
      "   -5.   -5.   -6.   -6.   -5.   -5.   -5.   -5.   -8.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5. -100.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -8.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.  -14.   -5.   -7.   -9.   -7.   -5.\n",
      "   -7.   -5.   -7.   -5.   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -6.   -5.   -5.   -9.   -6.   -5.   -5.   -7.   -5.   -7.\n",
      "   -9.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -7.   -8.   -7.\n",
      "   -5.   -5.   -6.   -5.   -6.   -7.   -5.   -5.   -5.   -6.   -5.   -5.\n",
      "   -6.   -5.   -6.   -5.   -5.   -5.   -5.  -12.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -7.   -8.]\n",
      "Rewards for Q_learning [-100.  -12. -100.   -5.  -27.  -16.  -13. -100.   -7.  -24.   -9.   -6.\n",
      "   -7.   -6.   -5.   -7. -100.   -5.  -10.   -6.   -8.   -8.   -6.   -7.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -8.   -5.   -5.   -5.   -5.   -5.\n",
      "   -7.   -7.   -5.   -6.   -6.   -5.   -5.   -6.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.  -12.   -5.   -6.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -8.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -7.   -7.   -7.   -6.   -7.   -5.   -5.  -10.   -5.\n",
      "   -6.   -7.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -7.   -7.   -7.\n",
      "   -5.   -9.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -9.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -9.   -6.   -5.\n",
      "   -5.   -5.   -7.   -6.   -5.   -6. -100.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -6.   -5.   -6.   -6.   -8.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -5.\n",
      "   -5.   -5.   -7.   -5.   -5.   -8.   -7.   -5.   -6.   -5.   -5.   -5.\n",
      "   -5. -100.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -8.   -5.   -5.   -5.   -5.   -5.   -5.   -6.  -10.   -5.\n",
      "   -7.   -6.   -5.   -5.   -7. -100.   -5.   -5.   -5.   -6.   -7.   -6.\n",
      "   -6.   -7.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -6.   -5.   -9.\n",
      "   -5.   -5.   -7.   -5.   -5.   -7.   -5.   -6.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -7.\n",
      "   -5.   -5.   -7.   -5.   -5.   -8.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.\n",
      "   -5.   -8.   -5.   -5.   -5.   -5.   -5.   -7.   -6.   -5.   -5.   -5.\n",
      "   -5.   -7.   -5.   -6.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -5.\n",
      "   -5.   -6.   -6.   -7.   -5.   -5.   -7.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -7.   -5.   -7.   -6.   -6.   -5.   -8.   -7.   -5.   -5.   -5.\n",
      "   -5.   -5.   -7.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -8.   -5.\n",
      "   -5.   -7.   -5.   -7.   -5.   -8.   -5.   -5.   -5.   -6.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5. -100.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -6.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -9.   -5.   -7.   -5.\n",
      "   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -6.   -5.   -5.\n",
      "   -5.   -5.   -9.   -5.   -5.   -5.   -5.   -8.   -7.   -5.   -5.   -6.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.\n",
      "   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -6.   -6.   -7.\n",
      "   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -7.   -5.   -5.   -7.   -5.   -5.   -7.   -7.   -5.   -5.\n",
      "   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -6.\n",
      "   -5.   -5.   -7.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -8. -100.\n",
      "   -5.   -8.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5.   -7.   -5.   -7.   -6.   -5.   -5.   -7.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      " -100.   -5.   -7.   -5.   -7.   -5.   -5.   -5.   -6.   -7.   -6.   -5.\n",
      "   -5.   -7.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -7. -100.\n",
      "   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -9.\n",
      "   -5.   -7.   -7.   -7.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -6.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -9.   -7.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -7.   -5.\n",
      "   -5.   -5. -100.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -9.\n",
      "   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -9.   -5.   -5.   -8.   -5.   -5.   -5.\n",
      "   -5.   -6.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.\n",
      "   -5.   -5.   -7.   -5.   -8.   -6.   -5.   -7.   -5.   -7.   -5.   -8.\n",
      "   -6.   -5.   -5.   -7.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -8.   -6.   -7.   -5.   -5.   -5.   -5.  -11.   -5.   -7.   -5.   -6.\n",
      "   -5.   -5.   -5.   -7.   -6.   -5. -100.   -5.   -5.   -7.   -5.   -5.\n",
      "   -5.   -7.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -7.   -5.  -10.\n",
      "   -5.   -5.   -5.   -5.   -6.   -6.   -5.   -5.   -5.   -5.   -5.   -5.\n",
      "   -7.   -5.   -6.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -7. -100.   -5.   -5.   -5.   -5.   -5.   -5.   -8.   -5.   -5.\n",
      "   -5.   -5.   -5.   -9.  -10.   -5.   -5.   -6.   -7.   -5.   -5.   -6.\n",
      "   -5.   -7.   -5.   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -7.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -6.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -7.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -5.\n",
      "   -5.   -7.   -5.   -5.   -6.   -5.   -9.   -5.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -7.   -6.   -5.   -6.   -6.   -6.   -9.   -5.   -5.\n",
      "   -5.   -7.   -5.   -5.   -5.   -5.   -7.   -5.   -5.   -7.   -5.   -5.\n",
      "   -5.   -5.   -6.   -6.   -5.   -5.   -9.   -6.   -5.   -5.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.\n",
      "   -7.   -5. -100.   -5.   -5.   -6.   -5.   -5.   -6.   -8.   -7.   -5.\n",
      "   -9.   -5.   -6.   -5.   -5.   -5.   -7.   -5.   -5.   -5.   -7.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5. -100.   -6.   -5.   -6.   -7.   -7.\n",
      "   -7.   -8.   -5.   -7.   -9.   -5.   -5.   -5.   -5.   -5.   -7.   -7.\n",
      "   -6.   -5.   -7.   -5.   -6.   -6.   -6.   -5.   -9.   -6.   -5.   -7.\n",
      "   -5.   -5.   -5.   -6.   -5.   -5.   -7.   -5.   -5.   -6.   -5.   -5.\n",
      "   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -5.   -6.   -6.   -5.   -5.\n",
      "   -5.   -5.   -6.   -5.   -5.   -5.   -5.   -5.   -5.   -7.   -5.   -9.\n",
      "   -7.   -6.   -5.   -5.]\n"
     ]
    }
   ],
   "source": [
    "figure_6_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
